{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 23.03.2019\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 07.04.2019\n",
    "Жёсткий дедлайн: 23:59MSK 14.04.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "Мы будем решать задачу предсказания опасных событий для страховой компании: [Liberty Mutual Group: Property Inspection Prediction](https://www.kaggle.com/c/liberty-mutual-group-property-inspection-prediction). Обучающая выборка состоит из засекреченных признаков целого и строкового типов. Целевой переменной являются счётчики $y \\in \\mathbb{Z}_+$.\n",
    "\n",
    "Работа состоит из следующих пунктов:\n",
    "* Предобработать данные [1 балл]\n",
    "* Написать свой алгоритм прогнозирования событий [2 балла]\n",
    "* Настроить линейные методы из библиотеки StatsModels для решения задачи [1 балл]\n",
    "* Настроить бустинг из библиотеки lightgbm для решения задачи [1 балл]\n",
    "\n",
    "Задания является дополнительным, то есть само по себе не учитывается в накопленной оценке. Все полученные за задание баллы являются бонусными, то есть их можно прибавить к оценке за любое теоретическое или практическое домашнее задание из курса.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 5 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-06-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-06-IvanovIvan.ipynb). \n",
    "\n",
    "Далее отправьте этот файл в AnyTask.\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценка:** 5 (10? Я сделал всё, но сумма баллов в ноутбуке только 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from lightgbm import LGBMModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('max_rows', 10)\n",
    "pd.set_option('max_columns', None)\n",
    "plt.style.use('bmh')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "__Задание 1 (1 балл).__ Загрузка и предобработка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hazard</th>\n",
       "      <th>T1_V1</th>\n",
       "      <th>T1_V2</th>\n",
       "      <th>T1_V3</th>\n",
       "      <th>T1_V4</th>\n",
       "      <th>T1_V5</th>\n",
       "      <th>T1_V6</th>\n",
       "      <th>T1_V7</th>\n",
       "      <th>T1_V8</th>\n",
       "      <th>T1_V9</th>\n",
       "      <th>T1_V10</th>\n",
       "      <th>T1_V11</th>\n",
       "      <th>T1_V12</th>\n",
       "      <th>T1_V13</th>\n",
       "      <th>T1_V14</th>\n",
       "      <th>T1_V15</th>\n",
       "      <th>T1_V16</th>\n",
       "      <th>T1_V17</th>\n",
       "      <th>T2_V1</th>\n",
       "      <th>T2_V2</th>\n",
       "      <th>T2_V3</th>\n",
       "      <th>T2_V4</th>\n",
       "      <th>T2_V5</th>\n",
       "      <th>T2_V6</th>\n",
       "      <th>T2_V7</th>\n",
       "      <th>T2_V8</th>\n",
       "      <th>T2_V9</th>\n",
       "      <th>T2_V10</th>\n",
       "      <th>T2_V11</th>\n",
       "      <th>T2_V12</th>\n",
       "      <th>T2_V13</th>\n",
       "      <th>T2_V14</th>\n",
       "      <th>T2_V15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>17</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>12</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>Y</td>\n",
       "      <td>71</td>\n",
       "      <td>21</td>\n",
       "      <td>Y</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>E</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>K</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>R</td>\n",
       "      <td>N</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>11</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hazard  T1_V1  T1_V2  T1_V3 T1_V4 T1_V5 T1_V6 T1_V7 T1_V8 T1_V9  T1_V10  \\\n",
       "Id                                                                            \n",
       "1        1     15      3      2     N     B     N     B     B     D       7   \n",
       "2        4     16     14      5     H     B     N     B     B     C      12   \n",
       "3        1     10     10      5     N     K     N     B     B     E      12   \n",
       "4        1     18     18      5     N     K     N     B     B     E       3   \n",
       "5        1     13     19      5     N     H     N     B     B     E       7   \n",
       "\n",
       "   T1_V11 T1_V12  T1_V13  T1_V14 T1_V15 T1_V16 T1_V17  T2_V1  T2_V2 T2_V3  \\\n",
       "Id                                                                          \n",
       "1       B      B      15       1      A      B      N     36     11     N   \n",
       "2       B      B      10       3      A      B      Y     78     10     Y   \n",
       "3       H      B      15       1      A      R      Y     71     21     Y   \n",
       "4       H      B      15       1      A      R      N     71     13     N   \n",
       "5       H      B      10       1      A      J      N     75     10     Y   \n",
       "\n",
       "    T2_V4 T2_V5  T2_V6  T2_V7  T2_V8  T2_V9  T2_V10 T2_V11 T2_V12 T2_V13  \\\n",
       "Id                                                                         \n",
       "1      10     B      2     37      1     11       6      Y      N      E   \n",
       "2      17     C      2     22      1     18       5      Y      Y      E   \n",
       "3      13     C      6     37      2     14       6      Y      Y      E   \n",
       "4      15     A      2     25      1      1       6      Y      N      C   \n",
       "5      11     B      1     22      1      2       7      N      N      E   \n",
       "\n",
       "    T2_V14  T2_V15  \n",
       "Id                  \n",
       "1        2       2  \n",
       "2        2       1  \n",
       "3        6       1  \n",
       "4        2       6  \n",
       "5        1       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', index_col='Id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50964, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Выделим категориальные и числовые признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical, numerical = list(), list()\n",
    "for col in data.columns[1:]:\n",
    "    if isinstance(data.loc[1, col], str):\n",
    "        categorical.append(col)\n",
    "    if isinstance(data.loc[1, col], np.int64):\n",
    "        numerical.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_V4      8\n",
      "T1_V5     10\n",
      "T1_V6      2\n",
      "T1_V7      4\n",
      "T1_V8      4\n",
      "T1_V9      6\n",
      "T1_V11    12\n",
      "T1_V12     4\n",
      "T1_V15     8\n",
      "T1_V16    18\n",
      "T1_V17     2\n",
      "T2_V3      2\n",
      "T2_V5      6\n",
      "T2_V11     2\n",
      "T2_V12     2\n",
      "T2_V13     5\n",
      "dtype: int64 \n",
      "\n",
      "T1_V1      19\n",
      "T1_V2      24\n",
      "T1_V3       9\n",
      "T1_V10      5\n",
      "T1_V13      4\n",
      "T1_V14      5\n",
      "T2_V1     100\n",
      "T2_V2      39\n",
      "T2_V4      22\n",
      "T2_V6       7\n",
      "T2_V7       7\n",
      "T2_V8       3\n",
      "T2_V9      25\n",
      "T2_V10      7\n",
      "T2_V14      7\n",
      "T2_V15     12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(data[categorical].nunique(), '\\n')\n",
    "    print(data[numerical].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['N', 'Y'], dtype=object),\n",
       " array(['N', 'Y'], dtype=object),\n",
       " array(['N', 'Y'], dtype=object),\n",
       " array(['Y', 'N'], dtype=object),\n",
       " array(['N', 'Y'], dtype=object))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['T1_V6'].unique(), data['T1_V17'].unique(), data['T2_V3'].unique(), data['T2_V11'].unique(), data['T2_V12'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'C', 'E', 'G', 'H', 'N', 'S', 'W']\n",
      "['A', 'B', 'C', 'D', 'E', 'H', 'I', 'J', 'K', 'L']\n",
      "['N', 'Y']\n",
      "['A', 'B', 'C', 'D']\n",
      "['A', 'B', 'C', 'D']\n",
      "['B', 'C', 'D', 'E', 'F', 'G']\n",
      "['A', 'B', 'D', 'E', 'F', 'H', 'I', 'J', 'K', 'L', 'M', 'N']\n",
      "['A', 'B', 'C', 'D']\n",
      "['A', 'C', 'D', 'F', 'H', 'N', 'S', 'W']\n",
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R']\n",
      "['N', 'Y']\n",
      "['N', 'Y']\n",
      "['A', 'B', 'C', 'D', 'E', 'F']\n",
      "['N', 'Y']\n",
      "['N', 'Y']\n",
      "['A', 'B', 'C', 'D', 'E']\n"
     ]
    }
   ],
   "source": [
    "for col in categorical:\n",
    "    print(sorted(data[col].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Нарисуем априорное распределение ответов $p(y)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6521: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  alternative=\"'density'\", removal=\"3.1\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Hazard'].plot(kind='hist', figsize=(10, 4), bins=40, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Hazard'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "В обобщённых линейных моделях, как и в машинном обучении в целом, мы проводим основную работу с апостериорным распределением $p(y|x)$, ведь именно в нём заключается информация о конкретной задаче. Здесь же мы знаем, что количество несчастных случаев во многом подчиняется распределению Пуассона, поэтому будем стараться моделировать именно его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выборке могут присутствовать шумовые признаки. Попробуем простейшим способом избавиться от них.\n",
    "\n",
    "Исследуйте абсолютное значение корреляции:\n",
    "* Признаков и отклика\n",
    "* Признаков и логарифма отклика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrs = [data[col].corr(data['Hazard']) for col in numerical]\n",
    "corrs = pd.DataFrame(np.abs(corrs), numerical, \n",
    "    ['abs corr with target']).sort_values('abs corr with target')\n",
    "corrs.plot(kind='bar', figsize=(10, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# corr with log(target)\n",
    "# place your code here\n",
    "\n",
    "log_target = np.log(data['Hazard'])\n",
    "\n",
    "corrs_log = [data[col].corr(log_target) for col in numerical]\n",
    "corrs_log = pd.DataFrame(np.abs(corrs_log), numerical, \n",
    "    ['abs corr with log(target)']).sort_values('abs corr with log(target)')\n",
    "corrs_log.plot(kind='bar', figsize=(10, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Уберите несколько наиболее неинформативных признаков. Лучше сделать это число гиперпараметром и потом настраивать его по функционалу качества. Может быть разумно также исследовать взаимосвязь признаков с логарифмом целевой переменной, поскольку мы предполагаем, что она неотрицательна и имеет распределение Пуассона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# place your code here\n",
    "data = data.drop(columns=corrs_log.index[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Закодируем значения категориальных признаков в числа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data[categorical] = data[categorical].apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Выделим столбец целевой переменной из наших данных. Множество значений случайной величины с распределением Пуассона начинается с нуля $\\{0, 1, 2...\\}$, поэтому вычтем единицу из целевой переменной. На самом деле, помимо прочего это приводит к существенному росту качества на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "objects = data.loc[:, 'T1_V1':]\n",
    "labels = data['Hazard'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Сделаем бинарное кодирование категориальных признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "mask = objects.columns.isin(categorical)\n",
    "onehot_encoder = OneHotEncoder(categorical_features=mask, sparse=False)\n",
    "objects_encoded = onehot_encoder.fit_transform(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Разделим выборку на обучающую и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_objects, test_objects, train_labels, test_labels = train_test_split(\n",
    "    objects_encoded, labels.as_matrix(), random_state=1, test_size=0.2, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "__Задание 2 (2 балла).__ Обучение регрессии с распределением Пуассона.\n",
    "\n",
    "Будем считать, что апостериорное распределение — это распределение Пуассона:\n",
    "\n",
    "$$p(y|\\lambda(x)) = \\frac{e^{-\\lambda(x)}\\lambda(x)^y}{y!}.$$\n",
    "\n",
    "Реализуйте функции для вычисления функционала качества (через метод максимального правдоподобия) и его градиентов — они были выведены на [семинаре](https://github.com/esokolov/ml-course-hse/blob/master/2017-spring/seminars/sem22-glm.pdf).\n",
    "\n",
    "Численные алгоритмы должны работать по возможности быстро, поэтому циклов быть не должно, и все операции должны быть векторными. Дальше мы будем использовать эту функцию в качестве аргумента другой функции. Можете попробовать добавить в модель регуляризатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def oracle(w, X, y):\n",
    "    \"\"\"\n",
    "    :param w: weights\n",
    "    :param X: features\n",
    "    :param y: target\n",
    "    :yield: loss, grad\n",
    "    \"\"\"\n",
    "    \n",
    "    # place your code here\n",
    "    prod = np.matmul(X, w)\n",
    "    exp_prod = np.exp(prod)\n",
    "    loss = (exp_prod - y.dot(prod)).sum()\n",
    "    grad = np.matmul(X.T, exp_prod - y)\n",
    "    \n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Добавьте к признакам столбец единиц, чтобы учесть вектор сдвига. Это важно. Библиотечные алгоритмы уже учитывают это внутри себя, поэтому им на вход нужно подавать исходную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_objects_bias = np.concatenate([train_objects, np.ones((train_objects.shape[0], 1))], axis=1)\n",
    "test_objects_bias = np.concatenate([test_objects, np.ones((test_objects.shape[0], 1))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Дальше воспользуйтесь функцией _scipy.optimize.minimize_, в ней реализовано множество градиентных методов оптимизации. Рекомендуется взять [L-BFGS-B](http://www.machinelearning.ru/wiki/images/6/65/MOMO17_Seminar6.pdf). Начальное приближение весов $w^{(0)}$ возьмите из стандартного нормального распределения как _np.random.randn_. Возможно, придётся запустить функцию несколько раз, прежде чем начальное приближение окажется удачным, и алгоритм покажет хороший результат. \n",
    "\n",
    "Сделайте прогноз для тестовых объектов. В качестве прогноза мы будем брать матожидание распределения $p(y | \\lambda(x))$ в данной точке, поэтому не забудьте взять экспоненту от выхода линейной модели, предсказывающей значение натурального параметра. Измерьте качество с помощью коэффициента Джини (чем выше – тем лучше) — именно он является целевой метрикой в соревновании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1/n_samples, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13870490297992838\n",
      "0.13870490297992838\n"
     ]
    }
   ],
   "source": [
    "# place your code here\n",
    "poisson_results = minimize(oracle, np.random.randn(train_objects_bias.shape[1]), \n",
    "                           args=(train_objects_bias, train_labels), method='L-BFGS-B', jac=True) #change parameters\n",
    "print(gini(test_labels, np.matmul(test_objects_bias, poisson_results.x)))\n",
    "print(gini(test_labels, np.exp(np.matmul(test_objects_bias, poisson_results.x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** Модель очень нестабильна. Это - лучший результат, и повторить что-либо похожее не получилось после серии запусков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "__Задание 3 (1 балл).__ Линейные модели из коробки.\n",
    "\n",
    "Запустите базовую линейную регрессию *sklearn.linear_model.LinearRegression* для предсказания логарифма целевой переменной и измерьте качество. Сравните полученный результат с работой вашего алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30831602830428023\n",
      "0.30831602830428023\n",
      "0.30831602830428023\n"
     ]
    }
   ],
   "source": [
    "# place your code here\n",
    "lin_model1 = LinearRegression()\n",
    "lin_model1.fit(train_objects, np.log(train_labels+1))\n",
    "\n",
    "print(gini(test_labels, lin_model1.predict(test_objects)))\n",
    "print(gini(test_labels, lin_model1.predict(test_objects)+1))\n",
    "print(gini(test_labels, np.exp(lin_model1.predict(test_objects)+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Познакомимся теперь с библиотекой [StatsModels](http://www.statsmodels.org/dev/index.html). Она предназначена скорее для описательной статистики, проверки гипотез и построения доверительных интервалов, чем для прогнозирования, — в отличие от scikit-learn, который создан специально для решения задач машинного обучения. В то же время в StatsModels реализован очень сильный алгоритм прогнозирования временных рядов – [SARIMAX](http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html), который при правильной настройке работает очень хорошо и занимает первые места в конкурсах ([Запись трансляции ML тренировки 03.02.18 | TrainMyData Ascott](https://www.youtube.com/watch?v=9MQEEyYDCQc&t=1101s)). \n",
    "\n",
    "Мы же попробуем обучить обобщённые линейные модели (модуль [GLM](http://www.statsmodels.org/dev/glm.html)) с различными вероятностными распределениями. Запустите алгоритм _sm.GLM_ на нескольких распределениях family, посмотрите на качество и проинтерпретируйте результаты. Синтаксис StatsModels немного отличается от scikit-learn тем, что здесь объекты и метки задаются в конструкторе модели, метод _fit()_ идёт без аргументов, и после обучения сохраняется новая модель с результатами и методом _predict_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gaussian__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3051258909210555"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#place your code here\n",
    "gaussian_sm_model = sm.GLM(train_labels, train_objects, sm.families.Gaussian())\n",
    "gaussian_sm_results = gaussian_sm_model.fit()\n",
    "pred_labels = gaussian_sm_results.predict(test_objects)\n",
    "gini(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Poisson__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30788848748736525"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#place your code here\n",
    "poisson_sm_model = sm.GLM(train_labels, train_objects, sm.families.Poisson())\n",
    "poisson_sm_results = poisson_sm_model.fit()\n",
    "pred_labels = poisson_sm_results.predict(test_objects)\n",
    "gini(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NegativeBinomial (Pascal)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30881021410858545"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place your code here\n",
    "negbinom_sm_model = sm.GLM(train_labels, train_objects, sm.families.NegativeBinomial())\n",
    "negbinom_sm_results = negbinom_sm_model.fit()\n",
    "pred_labels = negbinom_sm_results.predict(test_objects)\n",
    "gini(test_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Как видно, качество в последнем случае получилось лучше. На практике чаще используют именно отрицательное Биномиальное распределение. Оно является обобщением геометрического распределения и даёт некоторую свободу в выборе среднего и дисперсии для $p(y|x)$, тогда как в распределении Пуассона среднее и дисперсия совпадают. Если вам будет интересно, можете прочитать подробнее на вики [NegativeBinomial](https://en.m.wikipedia.org/wiki/Negative_binomial_distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4. (1 балл)__ Прогнозирование с помощью бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что бы мы ни делали, бустинг по-прежнему остаётся лучшим подходом для широкого круга задач — особенно если мы не работаем со структурированными данными вроде последовательностей или картинок. Бустинг хоть и сложный по своей структуре алгоритм, но вероятностные распределения не чужды и ему. Запустите _LGBMModel_, используя классическую регрессию и регрессию Пуассона. Настройте параметры, чтобы добиться наилучшего качества. В особенности обратите внимание на *objective*, *n_estimators*, *num_leaves* и *colsample_bytree*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35214717140988644\n"
     ]
    }
   ],
   "source": [
    "# objective='regression'\n",
    "lgbmmodel1 = LGBMModel(objective='regression')\n",
    "lgbmmodel1.fit(train_objects, train_labels)\n",
    "pred1 = lgbmmodel1.predict(test_objects)\n",
    "print(gini(test_labels, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3555657417114342\n"
     ]
    }
   ],
   "source": [
    "# objective='poisson'\n",
    "lgbmmodel2 = LGBMModel(objective='poisson')\n",
    "lgbmmodel2.fit(train_objects, train_labels)\n",
    "pred2 = lgbmmodel2.predict(test_objects)\n",
    "print(gini(test_labels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_scorer(estimator, X, y):\n",
    "    return gini(y, estimator.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.57507939, 1.02192736, 0.90942349, 1.12818141, 0.92680235,\n",
      "       1.30198507, 0.96567483, 0.98755007, 1.04380379, 1.87822027,\n",
      "       0.99692574, 1.8032166 , 1.68133659, 0.9656745 , 1.12505713,\n",
      "       0.77503948, 1.5407042 , 1.24068899, 1.20943694, 1.11880636,\n",
      "       0.88129535, 1.88447199, 0.8344173 , 1.54070406, 1.32506857,\n",
      "       1.01567731, 1.34069338, 1.69383683, 1.07505593, 0.90004368,\n",
      "       1.59070554, 1.02817693, 1.78134284, 1.371946  , 1.03755403,\n",
      "       1.20631146, 1.30944171, 1.06880517, 1.48132544, 1.55320539,\n",
      "       1.06567979, 1.18756166, 1.04380302, 1.57195435, 1.61883245,\n",
      "       1.09693012, 1.0531795 , 0.89692101, 1.02192826, 1.58758106,\n",
      "       1.43132315, 1.18756008, 1.52195163, 1.95634985, 1.27193947,\n",
      "       1.00317588, 0.96254969, 0.74691248, 1.08130536, 1.1813107 ,\n",
      "       1.5094523 , 0.92504706, 1.32819357, 1.31256695, 1.41257071,\n",
      "       1.27194042, 1.10630755, 1.30944095, 1.95009913, 2.06260543,\n",
      "       1.09068356, 1.68133645, 1.44382305, 1.5438293 , 1.69696202,\n",
      "       1.88447247, 1.66258421, 1.42819781, 2.11260886, 1.45632339,\n",
      "       1.88759818, 1.00317736, 1.56882873, 1.70633807, 1.6875864 ,\n",
      "       1.46882482, 1.55945482, 1.1281817 , 1.47195091, 1.61570692,\n",
      "       1.80946865, 1.37194366, 1.09068141, 1.17505989, 1.40007229,\n",
      "       1.12505665, 0.86254344, 1.13130751, 1.16568432, 0.89692216,\n",
      "       1.52820282, 1.30944242, 1.00005093, 0.90004702, 1.58758183,\n",
      "       1.39382105, 1.05630364, 1.04067802, 1.66570997, 1.40944633,\n",
      "       1.57195482, 1.09693117, 1.19381027, 1.2094368 , 0.87191863,\n",
      "       1.31569347, 1.60633407, 1.13443294, 0.72816215, 1.20943737,\n",
      "       1.41882267, 1.03130398, 0.9562983 , 1.51570344, 0.85941811,\n",
      "       0.85316796, 1.25631404, 1.57820616, 1.58133159, 1.03130217,\n",
      "       1.12818403, 0.98442464, 1.45007334, 1.32819219, 1.92197289,\n",
      "       1.03755322, 0.77191486, 1.0219285 , 1.12193279, 1.02817798,\n",
      "       1.40319686, 2.06885529, 1.52820387, 1.28756466, 1.31256628,\n",
      "       1.09380598, 1.10943103, 1.00942645, 0.84379268, 1.15631046,\n",
      "       1.21881356, 1.31569138, 0.94067326, 1.45945044, 1.25319037,\n",
      "       1.6250833 , 1.97509985, 1.43757315, 1.19693646, 1.48757472,\n",
      "       1.2531888 , 1.49070158, 1.5532042 , 1.23131223, 1.07193089,\n",
      "       1.48445125, 1.85009394, 1.46882582, 0.93754697, 1.1313086 ,\n",
      "       0.92817044, 1.04067893, 1.34069486, 1.47194991, 1.00942597,\n",
      "       1.52195392, 1.33131804, 1.85947051, 1.36569576, 1.50945253,\n",
      "       1.17818522, 1.04692807, 1.30944166, 1.56258006, 1.25943952,\n",
      "       1.00317645, 1.09380579, 1.33444314, 1.10943151, 1.4938262 ,\n",
      "       1.45319862, 1.55945368, 1.34381905, 1.06255436, 1.52507787,\n",
      "       0.80629072, 0.97505183, 1.04067903, 0.99692545, 1.11568198,\n",
      "       1.6782115 , 0.85316896, 1.60945754, 1.82509303, 1.20631208,\n",
      "       0.93442297, 1.95635047, 1.63133302, 1.25631557, 1.69383616,\n",
      "       0.99067602, 1.4594501 , 1.27506528, 0.95004854, 1.68446207,\n",
      "       1.40007124, 1.59695663, 1.22818823, 1.19381065, 1.09380512,\n",
      "       1.02192726, 1.00630298, 1.34381948, 1.40007157, 1.5250773 ,\n",
      "       1.30944147, 1.44694948, 1.35944352, 1.37194614, 1.21256251,\n",
      "       1.55007858, 1.19068608, 1.36256928, 1.45944905, 0.90004597,\n",
      "       1.47194939, 1.07505493, 1.32506967, 1.20943718, 1.04067793,\n",
      "       1.14068503, 1.12193198, 1.40988779, 1.86274986, 1.17858453,\n",
      "       1.28205419, 0.93742304, 1.284656  , 1.98191514, 1.15006032,\n",
      "       1.19104433, 1.63589826, 1.60110664, 1.9517004 , 1.04609766,\n",
      "       1.06010475, 2.32487965, 1.28415847, 1.57820611, 1.9532239 ,\n",
      "       1.5532033 , 2.08025346, 1.57796793, 1.12734952, 1.72755032,\n",
      "       2.0780623 , 0.92006097, 2.00511384, 2.72408061, 1.13996019,\n",
      "       1.50840435, 1.98388581, 1.31272449, 0.8344162 , 1.5157021 ,\n",
      "       1.68446312, 0.95317373, 1.39694657, 0.9594245 , 1.16568356,\n",
      "       1.00317521, 2.00322804, 1.14068308, 1.86259532, 1.38757086,\n",
      "       1.33756843, 1.14068317, 1.2438138 , 2.39074788, 1.10630617,\n",
      "       1.31569223, 1.12505903, 1.23756299, 1.40007143, 1.77509122,\n",
      "       1.11255589, 1.86571903, 0.98130074, 1.55945296, 0.91254544]), 'std_fit_time': array([0.0507795 , 0.03365975, 0.04002067, 0.01822289, 0.02085386,\n",
      "       0.01830484, 0.01457468, 0.03029765, 0.02688342, 0.0207296 ,\n",
      "       0.02296539, 0.02338637, 0.0211955 , 0.02072871, 0.00988189,\n",
      "       0.02538854, 0.02338636, 0.0125015 , 0.02538901, 0.01250088,\n",
      "       0.02119667, 0.023387  , 0.02338661, 0.02119535, 0.03878201,\n",
      "       0.04307588, 0.03617696, 0.03644604, 0.02296431, 0.02120021,\n",
      "       0.02072937, 0.01530964, 0.03277605, 0.04239249, 0.02119495,\n",
      "       0.02296514, 0.03029959, 0.02538877, 0.03029887, 0.02898164,\n",
      "       0.02072956, 0.03125188, 0.02296437, 0.02119624, 0.03903392,\n",
      "       0.01169222, 0.03062069, 0.01875183, 0.02539038, 0.02119587,\n",
      "       0.03217437, 0.02795154, 0.02538842, 0.030301  , 0.02724487,\n",
      "       0.02864231, 0.01593574, 0.02296485, 0.02688354, 0.03507983,\n",
      "       0.03903342, 0.02073058, 0.03827501, 0.00988227, 0.02538946,\n",
      "       0.01875064, 0.0268833 , 0.02688384, 0.04239198, 0.16887535,\n",
      "       0.0934435 , 0.05096921, 0.04698159, 0.05711426, 0.07435106,\n",
      "       0.0645032 , 0.0853576 , 0.07565217, 0.07288973, 0.05537876,\n",
      "       0.11198384, 0.04677276, 0.02898259, 0.03029988, 0.03423455,\n",
      "       0.039531  , 0.01822204, 0.03186988, 0.0375019 , 0.02724336,\n",
      "       0.03336685, 0.02296458, 0.03029971, 0.02688373, 0.02338687,\n",
      "       0.01397505, 0.03480133, 0.01875249, 0.03217696, 0.02724264,\n",
      "       0.02688336, 0.02296597, 0.03277725, 0.01593586, 0.02724428,\n",
      "       0.03187158, 0.02338682, 0.02724402, 0.02724484, 0.03617609,\n",
      "       0.02898216, 0.03878116, 0.01593614, 0.01250093, 0.03187088,\n",
      "       0.02500145, 0.01822216, 0.03644568, 0.03365957, 0.01875091,\n",
      "       0.03029962, 0.03125064, 0.02499956, 0.02209857, 0.02209914,\n",
      "       0.0272445 , 0.02338666, 0.02614617, 0.01822286, 0.03277659,\n",
      "       0.02688336, 0.01711742, 0.03029971, 0.02795114, 0.01976442,\n",
      "       0.04262122, 0.03365778, 0.03061967, 0.02688486, 0.01169429,\n",
      "       0.01822346, 0.05097105, 0.01169471, 0.01875149, 0.02420732,\n",
      "       0.02209769, 0.03277612, 0.01250176, 0.04074774, 0.01711694,\n",
      "       0.01711668, 0.01169386, 0.01531211, 0.0211951 , 0.04122422,\n",
      "       0.03277766, 0.02119592, 0.02614765, 0.02338777, 0.01531061,\n",
      "       0.03187035, 0.02539072, 0.03217446, 0.03336795, 0.00765395,\n",
      "       0.03125172, 0.02538859, 0.01976503, 0.02795224, 0.03365955,\n",
      "       0.03217572, 0.01875069, 0.03750264, 0.02296561, 0.02119674,\n",
      "       0.02898114, 0.02296483, 0.02614725, 0.03507735, 0.02119564,\n",
      "       0.02119541, 0.01397574, 0.0250013 , 0.01976529, 0.02119577,\n",
      "       0.02072977, 0.01397654, 0.03217554, 0.02795432, 0.03365711,\n",
      "       0.01976608, 0.01822205, 0.02209894, 0.01711737, 0.04262138,\n",
      "       0.035081  , 0.02724539, 0.01593566, 0.0182233 , 0.01875   ,\n",
      "       0.03776172, 0.01593447, 0.02614688, 0.03030019, 0.02688336,\n",
      "       0.04002128, 0.02688334, 0.03217546, 0.02724388, 0.03217607,\n",
      "       0.02898152, 0.03775979, 0.02119572, 0.03617662, 0.0302995 ,\n",
      "       0.0125001 , 0.03029868, 0.01593604, 0.01874993, 0.02614634,\n",
      "       0.02724467, 0.01593713, 0.03563301, 0.01593609, 0.01593347,\n",
      "       0.03029991, 0.02119615, 0.01976484, 0.02864285, 0.00765479,\n",
      "       0.02500106, 0.02296561, 0.02073072, 0.03217706, 0.02119526,\n",
      "       0.02864276, 0.03878191, 0.04571682, 0.02538916, 0.02538894,\n",
      "       0.0197651 , 0.01169389, 0.08147177, 0.08810202, 0.0725504 ,\n",
      "       0.05962342, 0.08264797, 0.05577062, 0.09031567, 0.07500301,\n",
      "       0.07465955, 0.06031044, 0.07678699, 0.06450597, 0.07411121,\n",
      "       0.03669845, 0.09406026, 0.06586808, 0.05502342, 0.2037344 ,\n",
      "       0.16105996, 0.18982705, 0.18591235, 0.11353392, 0.20657996,\n",
      "       0.2923074 , 0.01798067, 0.09347568, 0.12493282, 0.10912258,\n",
      "       0.17226989, 0.11053457, 0.05589926, 0.06139804, 0.16742113,\n",
      "       0.13088489, 0.02795301, 0.15201248, 0.13572069, 0.1678886 ,\n",
      "       0.10145923, 0.08232978, 0.06480484, 0.04980603, 0.04780599,\n",
      "       0.04026486, 0.08089317, 0.11422942, 0.1706014 , 0.09344311,\n",
      "       0.03878238, 0.03125145, 0.02500089, 0.02338572, 0.02724386,\n",
      "       0.03617642, 0.04800968, 0.08173391, 0.06043661, 0.1287021 ]), 'mean_score_time': array([0.16250892, 0.15000715, 0.11562986, 0.15090981, 0.13354387,\n",
      "       0.14063163, 0.10313015, 0.12500792, 0.12500672, 0.15938339,\n",
      "       0.14688215, 0.17188497, 0.14688263, 0.12500672, 0.12813096,\n",
      "       0.12500648, 0.15000744, 0.12500653, 0.13750834, 0.13438268,\n",
      "       0.0937551 , 0.16563387, 0.13438215, 0.15938363, 0.11875596,\n",
      "       0.12188153, 0.11875682, 0.14688458, 0.14375696, 0.12500572,\n",
      "       0.18125944, 0.16563468, 0.15625653, 0.14688225, 0.13750653,\n",
      "       0.15938344, 0.15938263, 0.13438153, 0.11250572, 0.18125935,\n",
      "       0.11875529, 0.1343812 , 0.17500982, 0.14375653, 0.16563368,\n",
      "       0.17813435, 0.13750715, 0.09688072, 0.11563101, 0.14063258,\n",
      "       0.16250839, 0.16250882, 0.16875882, 0.15313296, 0.15938334,\n",
      "       0.11875648, 0.14375854, 0.14375772, 0.11875606, 0.12813096,\n",
      "       0.16875873, 0.14688296, 0.15313225, 0.19063506, 0.17188497,\n",
      "       0.10938058, 0.13438163, 0.18125992, 0.17188334, 0.20313573,\n",
      "       0.15625601, 0.17813354, 0.12188172, 0.12813191, 0.18125992,\n",
      "       0.18438406, 0.15313368, 0.21251016, 0.18750935, 0.13125658,\n",
      "       0.16563597, 0.11875572, 0.14375887, 0.16875887, 0.15938344,\n",
      "       0.13750787, 0.15625825, 0.13125777, 0.17188268, 0.14063315,\n",
      "       0.1656333 , 0.14688354, 0.1281321 , 0.15625782, 0.13438129,\n",
      "       0.12500715, 0.09688001, 0.15625806, 0.15313382, 0.11250534,\n",
      "       0.14375806, 0.14375777, 0.13125677, 0.11250477, 0.18750973,\n",
      "       0.18125887, 0.16563411, 0.1312573 , 0.14375648, 0.13750753,\n",
      "       0.18751087, 0.15000768, 0.15000939, 0.17500882, 0.12188182,\n",
      "       0.15938225, 0.15938182, 0.17500973, 0.10000539, 0.16250882,\n",
      "       0.10938067, 0.14688177, 0.17813516, 0.13438096, 0.17188358,\n",
      "       0.10313148, 0.1718843 , 0.17188354, 0.14063177, 0.12813201,\n",
      "       0.1906333 , 0.10313077, 0.12500706, 0.14063325, 0.18125839,\n",
      "       0.1500072 , 0.12813191, 0.14063239, 0.1593832 , 0.16875825,\n",
      "       0.1312571 , 0.17188444, 0.15313368, 0.18438544, 0.12188201,\n",
      "       0.16563354, 0.1437572 , 0.1187561 , 0.1093801 , 0.16875882,\n",
      "       0.13750739, 0.17813416, 0.17813382, 0.13750753, 0.17500777,\n",
      "       0.14375834, 0.17813468, 0.1250073 , 0.14375787, 0.16563449,\n",
      "       0.18126001, 0.17813463, 0.15313354, 0.15313306, 0.1468821 ,\n",
      "       0.11875715, 0.17188339, 0.12813215, 0.13125739, 0.13438101,\n",
      "       0.09687986, 0.16875858, 0.15313244, 0.12188144, 0.13750739,\n",
      "       0.1718832 , 0.17813382, 0.15000801, 0.16875772, 0.14688325,\n",
      "       0.17188411, 0.1156302 , 0.15313411, 0.16875854, 0.15625854,\n",
      "       0.17188482, 0.11875601, 0.13125691, 0.14063263, 0.1406323 ,\n",
      "       0.16250844, 0.12500706, 0.1406323 , 0.13438096, 0.15313301,\n",
      "       0.14688282, 0.12500548, 0.13750648, 0.1156312 , 0.13750715,\n",
      "       0.15625858, 0.12500658, 0.18125982, 0.18125949, 0.15938239,\n",
      "       0.10625463, 0.16563339, 0.15625844, 0.16250868, 0.16875854,\n",
      "       0.10938063, 0.17500849, 0.14375691, 0.10312901, 0.14375701,\n",
      "       0.18438525, 0.1406323 , 0.16250777, 0.17188396, 0.13438263,\n",
      "       0.1625083 , 0.12813101, 0.11563058, 0.15313301, 0.15938396,\n",
      "       0.12188139, 0.14688158, 0.16875882, 0.18125892, 0.13125677,\n",
      "       0.16875916, 0.14375753, 0.1781342 , 0.13438144, 0.10625591,\n",
      "       0.14375768, 0.1125061 , 0.18125801, 0.17188349, 0.18438358,\n",
      "       0.1343822 , 0.16250858, 0.15463629, 0.16030684, 0.17111387,\n",
      "       0.16170812, 0.13469033, 0.14897513, 0.16875939, 0.16250844,\n",
      "       0.14084826, 0.17511725, 0.16130791, 0.17611756, 0.10627046,\n",
      "       0.143645  , 0.18750792, 0.14063196, 0.17813392, 0.20938568,\n",
      "       0.15938377, 0.22692552, 0.18768373, 0.24576459, 0.22735257,\n",
      "       0.16197028, 0.18054981, 0.16488862, 0.20893903, 0.16931343,\n",
      "       0.15270228, 0.16512966, 0.20492544, 0.13125701, 0.19688582,\n",
      "       0.11562901, 0.17813487, 0.20000958, 0.19688635, 0.11875615,\n",
      "       0.17188435, 0.16875863, 0.14063249, 0.1968843 , 0.1656342 ,\n",
      "       0.18750958, 0.1406323 , 0.15938382, 0.18438473, 0.10938015,\n",
      "       0.16563435, 0.14063101, 0.1187552 , 0.13125648, 0.18125944,\n",
      "       0.13750715, 0.22188878, 0.13438334, 0.18438478, 0.1156311 ]), 'std_score_time': array([7.65340975e-03, 7.65582357e-03, 7.65389643e-03, 8.55157389e-03,\n",
      "       8.12944908e-03, 9.88362561e-03, 7.65418834e-03, 1.44159474e-06,\n",
      "       1.39767044e-02, 6.25081074e-03, 7.65475289e-03, 1.28303757e-06,\n",
      "       7.65397416e-03, 1.24709099e-06, 6.25154984e-03, 2.10781442e-06,\n",
      "       7.65625184e-03, 2.57933203e-06, 6.25071529e-03, 7.65459712e-03,\n",
      "       2.22943682e-06, 7.65595973e-03, 1.25014306e-02, 6.24997616e-03,\n",
      "       1.25006557e-02, 6.25088221e-03, 7.65535636e-03, 7.65403319e-03,\n",
      "       6.25045304e-03, 6.21719590e-07, 7.65467494e-03, 7.65555096e-03,\n",
      "       1.02934995e-06, 7.65399372e-03, 6.25040535e-03, 6.25054849e-03,\n",
      "       1.53100409e-02, 7.65512266e-03, 6.24976186e-03, 7.65557040e-03,\n",
      "       7.65508383e-03, 7.65485014e-03, 6.25092994e-03, 6.25007160e-03,\n",
      "       7.65580402e-03, 7.65481127e-03, 1.16929343e-02, 6.24976170e-03,\n",
      "       7.65500590e-03, 9.93378957e-07, 7.65490855e-03, 7.65660224e-03,\n",
      "       6.25047689e-03, 6.25124004e-03, 1.16943361e-02, 7.65469442e-03,\n",
      "       6.25133522e-03, 6.25102522e-03, 7.65463602e-03, 6.25107296e-03,\n",
      "       6.25102535e-03, 7.65506429e-03, 6.25052453e-03, 6.24985696e-03,\n",
      "       1.34363201e-06, 1.25798282e-06, 7.65461667e-03, 7.65535629e-03,\n",
      "       3.27769587e-02, 4.07480688e-02, 3.56298757e-02, 2.11964123e-02,\n",
      "       1.16933930e-02, 6.25071532e-03, 2.11952452e-02, 1.16929343e-02,\n",
      "       2.68833030e-02, 3.21749835e-02, 9.88272098e-03, 1.24999285e-02,\n",
      "       1.59348572e-02, 1.25020266e-02, 6.24985699e-03, 1.16934567e-02,\n",
      "       1.16923354e-02, 1.16932528e-02, 9.48893964e-07, 7.65444135e-03,\n",
      "       9.88241928e-03, 1.29186794e-06, 1.25002146e-02, 7.65615445e-03,\n",
      "       6.25026237e-03, 9.88437960e-03, 7.65551201e-03, 9.88287166e-03,\n",
      "       1.16935715e-02, 8.58306885e-07, 1.16943362e-02, 6.25042918e-03,\n",
      "       6.25061993e-03, 6.25028615e-03, 7.65448030e-03, 6.25143061e-03,\n",
      "       1.22872340e-06, 7.65605708e-03, 7.65469443e-03, 7.65502555e-03,\n",
      "       6.25104937e-03, 6.25007161e-03, 9.88257015e-03, 7.65527842e-03,\n",
      "       7.65453869e-03, 6.24976172e-03, 1.16942469e-02, 6.24983317e-03,\n",
      "       6.25159745e-03, 1.16933293e-02, 7.65453874e-03, 7.65523955e-03,\n",
      "       9.22159176e-07, 7.65467492e-03, 7.65570677e-03, 7.65523971e-03,\n",
      "       9.88279627e-03, 7.65547328e-03, 9.88249470e-03, 9.88264553e-03,\n",
      "       3.23406696e-07, 6.25042932e-03, 1.53093206e-02, 7.65488912e-03,\n",
      "       1.51240840e-06, 9.88241930e-03, 7.65605719e-03, 7.65420775e-03,\n",
      "       6.24725855e-03, 1.09776158e-06, 6.24923715e-03, 1.16939920e-02,\n",
      "       7.65547310e-03, 9.88422874e-03, 6.25171676e-03, 6.25092985e-03,\n",
      "       6.24969010e-03, 7.65471390e-03, 6.25093017e-03, 1.25006080e-02,\n",
      "       9.88332408e-03, 1.16943998e-02, 6.25059612e-03, 1.25007869e-02,\n",
      "       7.65562900e-03, 6.25031009e-03, 6.24980931e-03, 6.25035770e-03,\n",
      "       7.65531739e-03, 1.62124634e-06, 6.25035779e-03, 7.65539519e-03,\n",
      "       7.65523946e-03, 1.25011444e-02, 6.25033380e-03, 6.25021459e-03,\n",
      "       7.65488908e-03, 7.65582349e-03, 1.05982355e-06, 6.24988085e-03,\n",
      "       7.65533687e-03, 7.65537587e-03, 6.25019085e-03, 6.25035776e-03,\n",
      "       6.24966627e-03, 6.25047688e-03, 1.16936352e-02, 9.88324862e-03,\n",
      "       7.65485025e-03, 7.65535640e-03, 6.24969048e-03, 7.65483071e-03,\n",
      "       1.79305989e-06, 1.25007392e-02, 6.25062001e-03, 1.16920932e-02,\n",
      "       9.88415335e-03, 1.39752649e-02, 7.65537583e-03, 7.65387683e-03,\n",
      "       1.45415789e-06, 1.45102730e-06, 7.65574559e-03, 4.15696997e-07,\n",
      "       9.88174072e-03, 7.65514227e-03, 6.25066774e-03, 7.65479173e-03,\n",
      "       1.31454933e-06, 1.16935843e-02, 7.65592082e-03, 6.25011939e-03,\n",
      "       9.88302246e-03, 1.64905705e-06, 7.65459710e-03, 7.65451922e-03,\n",
      "       6.24976167e-03, 6.25076300e-03, 1.24997259e-02, 9.88309785e-03,\n",
      "       7.65632967e-03, 6.25176432e-03, 9.60800251e-07, 6.25100158e-03,\n",
      "       6.24964268e-03, 7.65432484e-03, 6.25090604e-03, 6.25107294e-03,\n",
      "       2.78286676e-06, 7.65492800e-03, 9.88294708e-03, 7.65475281e-03,\n",
      "       7.65537576e-03, 6.25021506e-03, 7.65340964e-03, 6.25019090e-03,\n",
      "       6.25076310e-03, 6.25033389e-03, 7.65463602e-03, 6.25131134e-03,\n",
      "       7.65405207e-03, 7.65594039e-03, 1.16926411e-02, 1.53101577e-02,\n",
      "       7.65385760e-03, 7.65436347e-03, 6.25092992e-03, 6.25057222e-03,\n",
      "       6.25052460e-03, 1.59369705e-02, 1.97645370e-02, 1.16945910e-02,\n",
      "       1.87506914e-02, 1.59356518e-02, 2.43474537e-02, 1.88852365e-02,\n",
      "       1.98419594e-02, 1.09720815e-02, 1.78737272e-02, 9.69734138e-03,\n",
      "       1.16935969e-02, 1.25029922e-02, 9.54573653e-03, 1.94959353e-02,\n",
      "       1.25046914e-02, 7.13187281e-03, 7.44656372e-03, 5.81830261e-03,\n",
      "       2.42022061e-02, 1.39753183e-02, 1.24992371e-02, 1.59361381e-02,\n",
      "       6.24978545e-03, 3.17533581e-02, 3.68847720e-02, 4.86897560e-02,\n",
      "       4.90224753e-02, 1.11545603e-02, 9.34696429e-03, 4.79075413e-02,\n",
      "       3.76624914e-02, 1.29280392e-02, 5.57455308e-03, 1.71906799e-02,\n",
      "       1.47577949e-02, 1.59352870e-02, 3.64460417e-02, 7.65459720e-03,\n",
      "       7.65457762e-03, 2.29643297e-02, 3.77605290e-02, 1.25005722e-02,\n",
      "       2.61469652e-02, 1.53108294e-02, 3.23406696e-07, 1.59355582e-02,\n",
      "       7.65516166e-03, 1.71172006e-02, 1.97651401e-02, 1.82223790e-02,\n",
      "       1.16925392e-02, 9.88211785e-03, 7.65508376e-03, 8.17605410e-07,\n",
      "       7.65500601e-03, 7.65500590e-03, 7.65525901e-03, 1.16943998e-02,\n",
      "       2.49996782e-02, 1.59364934e-02, 1.16937626e-02, 2.33870409e-02]), 'param_colsample_bytree': masked_array(data=[0.6340385251650479, 0.11119680667187361,\n",
      "                   0.15586916730595152, 0.5347198473742494,\n",
      "                   0.28779353961201243, 0.4710000144606922,\n",
      "                   0.9236963548145117, 0.587168855975869,\n",
      "                   0.7271037100196325, 0.8755637288927931,\n",
      "                   0.2950481434660261, 0.6943136197974605,\n",
      "                   0.6625932914017024, 0.43488097836414685,\n",
      "                   0.8370702847105156, 0.17296526046876237,\n",
      "                   0.7680989486072965, 0.37455044596508513,\n",
      "                   0.8841942396289215, 0.19932893363237125,\n",
      "                   0.5620446186966679, 0.8036647423646476,\n",
      "                   0.22988135687243577, 0.471107825903025,\n",
      "                   0.4945203977526864, 0.5115227495097804,\n",
      "                   0.7773587882107825, 0.9609633643023151,\n",
      "                   0.49581171971899696, 0.31397797861416016,\n",
      "                   0.3923909398385672, 0.2277169936298066,\n",
      "                   0.8420240867204978, 0.3749225165218426,\n",
      "                   0.4761685096564008, 0.18203535125557757,\n",
      "                   0.8492066142072107, 0.5589313955192885,\n",
      "                   0.6636431741790647, 0.3469052316223026,\n",
      "                   0.9441123898657012, 0.25182035145294235,\n",
      "                   0.21075654120295892, 0.9323195512888698,\n",
      "                   0.5023788127020643, 0.3154044293679312,\n",
      "                   0.5221133293854752, 0.7022391579532242,\n",
      "                   0.6259570635539394, 0.9417974107836565,\n",
      "                   0.35640514305524795, 0.543115978203606,\n",
      "                   0.9659980574273919, 0.9427275454713274,\n",
      "                   0.7680835988692413, 0.6458761400685762,\n",
      "                   0.21439137138160427, 0.11282339406606566,\n",
      "                   0.9694113343097239, 0.9570237867132961,\n",
      "                   0.7295081049511466, 0.18419529965011805,\n",
      "                   0.3182984726732941, 0.18197495308868156,\n",
      "                   0.5789555821160584, 0.9050183203265487,\n",
      "                   0.666293429218502, 0.5154516314699359,\n",
      "                   0.8585064974515718, 0.8270136477631191,\n",
      "                   0.29779816579183216, 0.8953063947319679,\n",
      "                   0.9959257717919823, 0.8271962933089692,\n",
      "                   0.7106899422598779, 0.7435764232140434,\n",
      "                   0.9148979049342736, 0.22402313452669434,\n",
      "                   0.9565618407433233, 0.7597729381192027,\n",
      "                   0.9898598974561045, 0.452095962988177,\n",
      "                   0.6350397662571905, 0.8859279110283729,\n",
      "                   0.656571853114962, 0.7838939383311693,\n",
      "                   0.4611449201481771, 0.772819441791403,\n",
      "                   0.9670362321022685, 0.8530255069959972,\n",
      "                   0.632787244269748, 0.7533968337306085,\n",
      "                   0.7844025999870516, 0.5982831638871072,\n",
      "                   0.6757649580926302, 0.9008608214212219,\n",
      "                   0.5431036713676786, 0.15299465647791388,\n",
      "                   0.2000389381749706, 0.4646400763664966,\n",
      "                   0.6680257636956435, 0.33618800161969575,\n",
      "                   0.38867515290145227, 0.3653231678872124,\n",
      "                   0.3535328016018561, 0.24893718402464823,\n",
      "                   0.23709040866227865, 0.5196271505895719,\n",
      "                   0.8417077273421989, 0.6548375637007657,\n",
      "                   0.3572648059476131, 0.33160720986933184,\n",
      "                   0.6491038287486129, 0.178164869484593,\n",
      "                   0.23653792442642782, 0.686000000700596,\n",
      "                   0.4704828566553797, 0.12329462792232826,\n",
      "                   0.198144098491158, 0.5091533154451762,\n",
      "                   0.6507590598445704, 0.3658211747638409,\n",
      "                   0.16810155594708398, 0.8322766832913966,\n",
      "                   0.10576550925523748, 0.45601931439729515,\n",
      "                   0.23897084490267767, 0.45262852698058087,\n",
      "                   0.6255541901624335, 0.35634344792715855,\n",
      "                   0.24998594295299367, 0.7669398682435363,\n",
      "                   0.897150935571347, 0.31491827784621806,\n",
      "                   0.6546969491572012, 0.3663858250595775,\n",
      "                   0.11089808919331559, 0.11071520271458847,\n",
      "                   0.33499836040104725, 0.25073574364293616,\n",
      "                   0.44784407702950957, 0.9403051899627942,\n",
      "                   0.6088418415713118, 0.1752838268154666,\n",
      "                   0.6419914590110202, 0.30714635295584103,\n",
      "                   0.6450582725752908, 0.6949935144602688,\n",
      "                   0.35717067639812383, 0.16689899827891774,\n",
      "                   0.9906718772681412, 0.5976394866488967,\n",
      "                   0.1603396972687014, 0.8108848366032662,\n",
      "                   0.1766518064770613, 0.5757462412328647,\n",
      "                   0.9469306559375079, 0.9961324990629057,\n",
      "                   0.8531529257244939, 0.5077974236246021,\n",
      "                   0.5273175154715097, 0.3386656358824352,\n",
      "                   0.4844624724869392, 0.7781267850834566,\n",
      "                   0.44154846836721284, 0.9982627786388367,\n",
      "                   0.6531245950413587, 0.9363606284403434,\n",
      "                   0.34846602143635386, 0.23907292016373563,\n",
      "                   0.9503058474119538, 0.24270561897952297,\n",
      "                   0.8425559461407449, 0.9539588768000146,\n",
      "                   0.4073109425564988, 0.36168139683410905,\n",
      "                   0.5231960085145012, 0.7613917683444177,\n",
      "                   0.2919273412558355, 0.45638528973770354,\n",
      "                   0.15806416139462698, 0.8982083957335393,\n",
      "                   0.29113827278801396, 0.67447235712385,\n",
      "                   0.46366248687252953, 0.23288132378911566,\n",
      "                   0.2737198732071229, 0.5149314294604318,\n",
      "                   0.6299847075032537, 0.7780254658530212,\n",
      "                   0.7595375510973837, 0.8432477888812052,\n",
      "                   0.4298482718301969, 0.5157343397802021,\n",
      "                   0.9720707082182733, 0.1057809698163946,\n",
      "                   0.45777167008535924, 0.5099063784491388,\n",
      "                   0.6424339307842207, 0.8232890957004106,\n",
      "                   0.6065803143820755, 0.20717162343087409,\n",
      "                   0.4345769484179547, 0.5808306003455865,\n",
      "                   0.18055710557046065, 0.6761192701579011,\n",
      "                   0.8047230126510647, 0.7870105725502932,\n",
      "                   0.8069181625033763, 0.6262055719182124,\n",
      "                   0.7995605365888756, 0.3782803427160889,\n",
      "                   0.7733101394595191, 0.7147223886772507,\n",
      "                   0.908892585339458, 0.24021276759037746,\n",
      "                   0.9758123942682394, 0.39787851547533826,\n",
      "                   0.4944660604721455, 0.6351759691377785,\n",
      "                   0.2362602711914543, 0.45691776900368386,\n",
      "                   0.8165162446037298, 0.5151478748397048,\n",
      "                   0.5353763300650954, 0.59256981554922,\n",
      "                   0.8933758689780991, 0.26944630861610824,\n",
      "                   0.26260606062524383, 0.7104592135662116,\n",
      "                   0.8059437162573423, 0.8228271593255101,\n",
      "                   0.5803092738606407, 0.8052765768665858,\n",
      "                   0.40663206839129906, 0.8404673107445133,\n",
      "                   0.8015039430919477, 0.7224476749319684,\n",
      "                   0.38796851970907553, 0.1661082926884708,\n",
      "                   0.8258225949520992, 0.3019732176075895,\n",
      "                   0.5089736767734521, 0.6623876528985237,\n",
      "                   0.3135242177052996, 0.4997818813319299,\n",
      "                   0.1666798605381861, 0.7124946614291792,\n",
      "                   0.5370090554256027, 0.4470269769191365,\n",
      "                   0.8292078675622013, 0.7849490642198346,\n",
      "                   0.2967475348648317, 0.4383678370326952,\n",
      "                   0.6883639949386551, 0.44730871160993046,\n",
      "                   0.9704232434679176, 0.9308438349148834,\n",
      "                   0.385886115942048, 0.5261206267708649,\n",
      "                   0.8201289510249773, 0.5329109575032456,\n",
      "                   0.5665466417976379, 0.11595889480298804,\n",
      "                   0.20902859813886768, 0.6095554759088277,\n",
      "                   0.11484128004489738, 0.9402993079145765,\n",
      "                   0.972940938258162, 0.15633889152293817,\n",
      "                   0.6999585630579214, 0.7137238120071548,\n",
      "                   0.34284897090432787, 0.1492273147390387,\n",
      "                   0.16976930096837606, 0.856316562864809,\n",
      "                   0.13591344605956826, 0.2080516155897475,\n",
      "                   0.10581891089920381, 0.8668917995838026,\n",
      "                   0.13211358261547682, 0.6878613107313024,\n",
      "                   0.20509891786653625, 0.7477710378105493,\n",
      "                   0.6582894989892073, 0.20749495826355557,\n",
      "                   0.16485752447367513, 0.7540834345600514,\n",
      "                   0.963777722299522, 0.8296059097110555,\n",
      "                   0.5304601081412211, 0.5949928782504383,\n",
      "                   0.9385795527440358, 0.5942183946736928,\n",
      "                   0.6153575552380695, 0.1680998075774463,\n",
      "                   0.5453634389721779, 0.3177141796137971,\n",
      "                   0.8320462128431236, 0.10252002908234097],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.13721353001951353, 0.1120419537087114,\n",
      "                   0.2983175872412631, 0.10164946637519832,\n",
      "                   0.01609676463251509, 0.2191629560787668,\n",
      "                   0.1150873944828273, 0.08917670733275132,\n",
      "                   0.18910884724124324, 0.034873060784126136,\n",
      "                   0.004398464308455438, 0.03723682634121699,\n",
      "                   0.013027152761594408, 0.06625796106846611,\n",
      "                   0.16393320243791407, 0.08787995956808402,\n",
      "                   0.10761030207262089, 0.12750316021829625,\n",
      "                   0.11386962309689633, 0.10126868369933915,\n",
      "                   0.19093364391415182, 0.03373131563022606,\n",
      "                   0.18689508877328131, 0.024305850003930346,\n",
      "                   0.034134626185190246, 0.15224443286006745,\n",
      "                   0.20119754232529377, 0.08358849899242443,\n",
      "                   0.07723730330196749, 0.20898988949325453,\n",
      "                   0.0006283745734353392, 0.005564300385676136,\n",
      "                   0.05700963458097962, 0.2861538345128047,\n",
      "                   0.1173173677005946, 0.040431862591854335,\n",
      "                   0.05335521043939724, 0.1300330146822176,\n",
      "                   0.02204870971282969, 0.021547029879433376,\n",
      "                   0.13419360131779975, 0.021452932411615062,\n",
      "                   0.013788964965471759, 0.1375429719431471,\n",
      "                   0.007589705904968035, 0.0977987504824806,\n",
      "                   0.06562687413111504, 0.2739214709362535,\n",
      "                   0.18192919881000247, 0.0020970943895581486,\n",
      "                   0.05775443774336092, 0.08676451894947784,\n",
      "                   0.03531551476485263, 0.031467150704129115,\n",
      "                   0.07238452210296664, 0.1730648150252108,\n",
      "                   0.036916855320430625, 0.3103731373665605,\n",
      "                   0.1310434557350093, 0.06808928776723219,\n",
      "                   0.011010327538498663, 0.018818657262798785,\n",
      "                   0.033913113433316544, 0.052477611269077976,\n",
      "                   0.0096445468087862, 0.38494959031066195,\n",
      "                   0.09003491211900631, 0.038552334775197976,\n",
      "                   0.009401710541715205, 0.054142832211196194,\n",
      "                   0.020079400653059146, 0.02005189314158819,\n",
      "                   0.21578778827840575, 0.1595141180305381,\n",
      "                   0.14659124218958608, 0.0962120802883251,\n",
      "                   0.20965375871393088, 0.09837419407892008,\n",
      "                   0.0701533999318326, 0.09917727494194369,\n",
      "                   0.08477055904917222, 0.15379387230964847,\n",
      "                   0.051624484796081005, 0.14761031721794476,\n",
      "                   0.031262936896216086, 0.20341438278618182,\n",
      "                   0.02080498129883168, 0.07289345473905243,\n",
      "                   0.04880243712542856, 0.15652319807376272,\n",
      "                   0.0038904308262780285, 0.024087143514587097,\n",
      "                   0.09142938134452808, 0.07314329367541503,\n",
      "                   0.3725910676406671, 0.24433208973784248,\n",
      "                   0.22816136052793334, 0.0714237147792365,\n",
      "                   0.15198220066353338, 0.42463513503131867,\n",
      "                   0.15512315938775093, 0.06981729419763069,\n",
      "                   0.07915588762718129, 0.46861073183344204,\n",
      "                   0.03697261106616251, 0.018508738913997572,\n",
      "                   0.09193169938578101, 0.1080642860044764,\n",
      "                   0.08466316296417803, 0.19440041723943058,\n",
      "                   0.07137271132888452, 0.014554583797159274,\n",
      "                   0.04287528276562599, 0.13479323578340255,\n",
      "                   0.05841722933685242, 0.05149915731091353,\n",
      "                   0.027088420862536558, 0.07267832091695267,\n",
      "                   0.20578117206295488, 0.06415673917086971,\n",
      "                   0.012760782136666152, 0.06967256258483989,\n",
      "                   0.06078013384265866, 0.16321774570797998,\n",
      "                   0.002262565128818962, 0.19924965862634203,\n",
      "                   0.22290195690879944, 0.08825712997685436,\n",
      "                   0.022410048517253797, 0.017310605174929015,\n",
      "                   0.014532289791370005, 0.09671771752823162,\n",
      "                   0.19735472664584328, 0.021032602728267114,\n",
      "                   0.030183866524842763, 0.08549874571613028,\n",
      "                   0.0436041264529394, 0.016436791638869127,\n",
      "                   0.016097346669252374, 0.03327556328622878,\n",
      "                   0.003933507468437052, 0.02553222046609372,\n",
      "                   0.060503568445079314, 0.057393617194400615,\n",
      "                   0.28705191020813964, 0.009153929892893639,\n",
      "                   0.1023211084757759, 0.2657116015051434,\n",
      "                   0.3143509323759226, 0.2999059901259952,\n",
      "                   0.1430203710651645, 0.05098680946369856,\n",
      "                   0.09969219366211418, 0.27306664090667104,\n",
      "                   0.04509491318806991, 0.010233295383476905,\n",
      "                   0.08764228062115931, 0.10849722722061672,\n",
      "                   0.07869456720077828, 0.16248728123245748,\n",
      "                   0.0666711222880479, 0.12393140088267374,\n",
      "                   0.003750560069163047, 0.0677957507816428,\n",
      "                   0.07337494051280784, 0.1571734593649373,\n",
      "                   0.01703523012369829, 0.16188564964555138,\n",
      "                   0.18738336322827437, 0.054018739878122696,\n",
      "                   0.14932698673275538, 0.049057409483257236,\n",
      "                   0.04357816761647343, 0.10597535318232201,\n",
      "                   0.08371030304184437, 1.0399361785529096e-05,\n",
      "                   0.013403328230611956, 0.0006038977751746933,\n",
      "                   0.05410936009211364, 0.00403281441127091,\n",
      "                   0.1762735496350967, 0.11596861906319711,\n",
      "                   0.007795019328192453, 0.19362912528256127,\n",
      "                   0.004161897804514534, 0.08527641241310609,\n",
      "                   0.20579163251957563, 0.15253372042971425,\n",
      "                   0.062400794055480095, 0.26049751934184057,\n",
      "                   0.03080266974973478, 0.06778299847365227,\n",
      "                   0.14890822107759868, 0.05194847550994865,\n",
      "                   0.02223147481204618, 0.019005172416508367,\n",
      "                   0.1702152279519259, 0.13838276125950097,\n",
      "                   0.33802739597375675, 0.1610211212470255,\n",
      "                   0.04513576683791684, 0.004979459852160546,\n",
      "                   0.07826162423718752, 0.03324367057236511,\n",
      "                   0.015335096913388514, 0.14496618711076464,\n",
      "                   0.0258886597364877, 0.12605900111298482,\n",
      "                   0.09190393108750827, 0.07266987254802497,\n",
      "                   0.08159582889435449, 0.1328809343392834,\n",
      "                   0.04784670665840694, 0.2309972835688647,\n",
      "                   0.08968229348339007, 0.026426887899814646,\n",
      "                   0.22304569271488361, 0.007601399651179419,\n",
      "                   0.06763878550195272, 0.14678551275726168,\n",
      "                   0.02629895604833439, 0.03100838803589906,\n",
      "                   0.2510202253073454, 0.2753190824945859,\n",
      "                   0.10812119130517, 0.197284135057062,\n",
      "                   0.017981441553081894, 0.09320926400146927,\n",
      "                   0.08206280487820534, 0.04303124240226937,\n",
      "                   0.018280912718509845, 0.08827562827057835,\n",
      "                   0.03676918354378766, 0.20307784082849772,\n",
      "                   0.1828468098989392, 0.003635735313392364,\n",
      "                   0.22534190269565135, 0.05359881733594344,\n",
      "                   0.012312041715874602, 0.09313113521012406,\n",
      "                   0.24650978657602943, 0.012904096210348714,\n",
      "                   0.20220893093648287, 0.011419963622314391,\n",
      "                   0.009877030399307228, 0.19333962789115622,\n",
      "                   0.0018279261941646292, 0.07896609608289766,\n",
      "                   0.035561460288336615, 0.10159089652837348,\n",
      "                   0.11251272983731386, 0.14957223373320247,\n",
      "                   0.034728788392836385, 0.01575237923495488,\n",
      "                   0.1793077392923187, 0.2344951678621305,\n",
      "                   0.026171409661677043, 0.09101047586881111,\n",
      "                   0.040054425671162665, 0.033152920692194665,\n",
      "                   0.04032794610301893, 0.02768130022446208,\n",
      "                   0.23198305790338664, 0.05827023017060176,\n",
      "                   0.03763438744879135, 0.0155506257450672,\n",
      "                   0.05237595334827582, 0.0024234918474434295,\n",
      "                   0.02861097599219288, 0.08845434236678876,\n",
      "                   0.14252835385552787, 0.01558872576434775,\n",
      "                   0.08659777814555442, 0.15835738678180444,\n",
      "                   0.13755602521281593, 0.031368526171166054,\n",
      "                   0.018398110885914594, 0.03798156680730207,\n",
      "                   0.02156176993256023, 0.10353637943763289,\n",
      "                   0.23846593323338558, 0.03815184099053931,\n",
      "                   0.26542766547000257, 0.060889734983300574,\n",
      "                   0.029531624411909624, 0.03215832621780017,\n",
      "                   0.11506140246353198, 0.1349639924731957,\n",
      "                   0.03733246205206642, 0.14075586661796144,\n",
      "                   0.019155707192077584, 0.042327327732628484,\n",
      "                   0.010366189848015248, 0.2529058868342804,\n",
      "                   0.07110509555863452, 0.04882632507225002,\n",
      "                   0.04583710627987326, 0.09319006570384314,\n",
      "                   0.03908150645912525, 0.23132578153876704],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_num_leaves': masked_array(data=[49, 39, 17, 58, 20, 39, 18, 24, 51, 43, 27, 45, 30, 19,\n",
      "                   51, 18, 26, 17, 48, 21, 17, 45, 35, 31, 12, 33, 23, 27,\n",
      "                   34, 35, 53, 44, 30, 58, 40, 35, 41, 40, 15, 58, 31, 18,\n",
      "                   49, 27, 45, 56, 23, 21, 37, 48, 33, 54, 52, 40, 49, 36,\n",
      "                   29, 30, 25, 23, 52, 25, 26, 58, 58, 23, 30, 54, 43, 54,\n",
      "                   16, 57, 17, 21, 51, 49, 56, 50, 45, 13, 22, 25, 21, 55,\n",
      "                   33, 40, 35, 26, 49, 41, 47, 34, 26, 41, 46, 52, 17, 32,\n",
      "                   30, 38, 34, 22, 25, 40, 59, 49, 54, 32, 24, 33, 58, 32,\n",
      "                   28, 45, 17, 42, 38, 49, 14, 42, 12, 31, 51, 31, 59, 20,\n",
      "                   47, 42, 22, 19, 54, 13, 27, 23, 54, 32, 19, 31, 34, 41,\n",
      "                   18, 56, 24, 56, 31, 40, 40, 43, 28, 51, 59, 54, 56, 48,\n",
      "                   49, 29, 55, 12, 36, 46, 57, 53, 29, 36, 32, 20, 54, 22,\n",
      "                   41, 16, 13, 41, 38, 13, 27, 45, 50, 40, 38, 31, 52, 25,\n",
      "                   26, 55, 38, 44, 14, 20, 24, 54, 50, 16, 26, 21, 41, 29,\n",
      "                   34, 41, 53, 47, 30, 14, 47, 56, 38, 20, 47, 34, 57, 40,\n",
      "                   12, 48, 31, 29, 27, 57, 51, 42, 50, 46, 35, 15, 24, 54,\n",
      "                   32, 21, 35, 43, 52, 22, 55, 37, 53, 35, 25, 38, 46, 33,\n",
      "                   30, 55, 44, 28, 15, 16, 19, 36, 13, 25, 36, 30, 20, 59,\n",
      "                   16, 35, 20, 54, 51, 24, 43, 39, 21, 36, 12, 41, 47, 20,\n",
      "                   52, 33, 44, 23, 54, 30, 59, 15, 50, 13, 52, 39, 34, 13,\n",
      "                   39, 41, 26, 43, 40, 47, 18, 40, 59, 19, 41, 20, 16, 47,\n",
      "                   51, 22, 52, 18, 47, 18],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_objective': masked_array(data=['poisson', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'regression', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'poisson', 'poisson',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'regression', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'poisson', 'poisson', 'poisson',\n",
      "                   'poisson', 'poisson', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'poisson', 'poisson',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'regression', 'poisson', 'poisson', 'poisson',\n",
      "                   'regression', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'poisson', 'poisson',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'poisson', 'regression', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'poisson', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'regression', 'regression', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'poisson', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'poisson', 'poisson', 'poisson', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'poisson',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'regression',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'regression', 'regression', 'poisson', 'poisson',\n",
      "                   'regression', 'regression', 'poisson', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'poisson', 'poisson',\n",
      "                   'regression', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'poisson', 'regression', 'regression',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'regression', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'regression', 'poisson',\n",
      "                   'poisson', 'regression', 'poisson', 'regression',\n",
      "                   'regression', 'regression', 'regression', 'poisson',\n",
      "                   'poisson', 'poisson', 'poisson', 'regression',\n",
      "                   'regression', 'poisson'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_alpha': masked_array(data=[0.43802318107538296, 0.048487138089235444,\n",
      "                   0.3954342073494389, 1.2158459825844874,\n",
      "                   0.16950051749815478, 0.6343588032506453,\n",
      "                   2.122506215554823, 0.7336897379649074,\n",
      "                   0.8258132695968837, 0.5764120358710461,\n",
      "                   0.37281292281281436, 0.30668062112157873,\n",
      "                   0.06771574343825915, 1.5979050888865756,\n",
      "                   1.1443076702514239, 0.370894917252928,\n",
      "                   1.241542060791901, 1.8960224830956147,\n",
      "                   1.6476516747993188, 0.605628663307387,\n",
      "                   0.2429480859030139, 2.573240338923107,\n",
      "                   1.454635127197847, 2.0301317467345026,\n",
      "                   0.7747426521377447, 0.06920113383622226,\n",
      "                   2.4697005100735727, 0.9929988413028956,\n",
      "                   0.10887987924169945, 0.18621245553570853,\n",
      "                   0.21891625631372205, 0.7216859496784237,\n",
      "                   0.6981828821055034, 0.19460814545218844,\n",
      "                   1.6774770543519928, 0.17518971429550403,\n",
      "                   0.9742113191447452, 0.7155147118224264,\n",
      "                   0.7529221655560803, 0.22979003495391523,\n",
      "                   0.513623392696352, 0.19889239476433715,\n",
      "                   0.05758116251676125, 0.34770755434380496,\n",
      "                   4.586403037533275, 3.411869641710405,\n",
      "                   1.1220785000688507, 0.4066984032074417,\n",
      "                   2.5635655849094863, 0.7803534607571271,\n",
      "                   0.30974501670387095, 0.5493771108593697,\n",
      "                   0.5867862660736856, 0.9754504342542487,\n",
      "                   2.548679130544533, 0.8196164817177749,\n",
      "                   0.13448638622772957, 1.3557500285625643,\n",
      "                   0.0874873906979539, 1.420496320868553,\n",
      "                   0.6257162041684075, 0.09881785655139512,\n",
      "                   1.2260021102455307, 0.7419666860269557,\n",
      "                   1.5850573794915421, 3.4701955251974033,\n",
      "                   0.0002713721231523572, 1.1561145400002688,\n",
      "                   1.9513085162196246, 5.243228754470758,\n",
      "                   0.05210325406949956, 2.0926617930631433,\n",
      "                   1.1136860646857563, 0.055170535951142664,\n",
      "                   1.7612283411688938, 1.1887857553591914,\n",
      "                   0.556405508868846, 0.07428299646942262,\n",
      "                   1.5203015023702902, 4.522598020250046,\n",
      "                   1.1416400002662785, 0.09844407737366118,\n",
      "                   0.6147389667289054, 2.6503485771255644,\n",
      "                   3.3504316238851093, 1.380846418956336,\n",
      "                   0.7435756159291053, 1.6801776879657317,\n",
      "                   0.24580012402947657, 0.02368577946156917,\n",
      "                   0.430341897643021, 0.20742549623079165,\n",
      "                   0.33467895238225104, 0.3758830898145239,\n",
      "                   4.705373381691776, 0.2922416279154702,\n",
      "                   0.33916404869803773, 2.332993636161555,\n",
      "                   0.3416441594747109, 1.1271718030795692,\n",
      "                   0.28191064957070633, 0.712380727878081,\n",
      "                   0.4114921876681898, 0.18440521780105915,\n",
      "                   0.9005700177292141, 0.6747931486753183,\n",
      "                   0.07817610044433063, 0.5059894906149927,\n",
      "                   0.1270043097778588, 0.5755320805049392,\n",
      "                   1.2697597586477538, 1.5894419242373896,\n",
      "                   3.359229767338584, 0.6736711849323584,\n",
      "                   0.42897002233064147, 0.30872740715279184,\n",
      "                   0.5247563711717522, 0.019770831156341928,\n",
      "                   0.15068402304544562, 0.2312273010420005,\n",
      "                   0.12991649198891295, 0.8910039781497688,\n",
      "                   1.5630636841010543, 0.4009041834635661,\n",
      "                   0.44218030559043164, 0.602389070288156,\n",
      "                   2.261714383391091, 0.09443393064125023,\n",
      "                   0.4492603302066354, 0.7211043011031748,\n",
      "                   0.5621605933899536, 0.838790687367086,\n",
      "                   0.6375075373063976, 0.7433185759589663,\n",
      "                   0.5626257827382358, 0.8400651303422296,\n",
      "                   1.9642079805582973, 0.3619195937727834,\n",
      "                   0.13130620385714134, 0.651678482971365,\n",
      "                   0.10193601241623848, 3.0264682262543077,\n",
      "                   6.234794866586649, 0.13885501293231126,\n",
      "                   0.20442753704033587, 1.951704978895264,\n",
      "                   0.26009118053587915, 0.19998217585232095,\n",
      "                   1.434583575973427, 1.5191643192536244,\n",
      "                   0.4125867919824576, 1.0954095594954478,\n",
      "                   1.3657203868947152, 1.304029817641542,\n",
      "                   0.2090799375503098, 0.28693480961820117,\n",
      "                   0.44623011896783465, 0.3706805412923388,\n",
      "                   3.6030650092014427, 0.3561183216280932,\n",
      "                   1.2624171627733656, 0.0009221373459273397,\n",
      "                   0.2482604864613469, 0.4526837251285327,\n",
      "                   2.3757904499640947, 0.8787289061802923,\n",
      "                   4.1821606025086275, 1.2918874900357864,\n",
      "                   0.4078227923082333, 3.6072348298973953,\n",
      "                   2.93965392647211, 2.6044743937190287,\n",
      "                   2.2955857453991335, 0.37423892762851574,\n",
      "                   0.45179514337660204, 0.6484197440506422,\n",
      "                   1.3429371403317714, 0.41994521074711594,\n",
      "                   1.7944334461077311, 1.4016176992297287,\n",
      "                   1.193299506542173, 3.4287199600411267,\n",
      "                   0.296553099661214, 0.30106597093900184,\n",
      "                   0.12799189677278577, 0.16915354827791498,\n",
      "                   0.6162061325716566, 0.2576212283874702,\n",
      "                   2.8163048756804674, 1.8632262414049605,\n",
      "                   0.556939754829891, 0.24943291894012334,\n",
      "                   0.3274949775772318, 1.112625161369371,\n",
      "                   0.061032212836918974, 0.04819589137841335,\n",
      "                   0.4379962334541965, 1.3249008389583832,\n",
      "                   0.2404124199873754, 7.032862828180445,\n",
      "                   0.6081214412279128, 2.155719877834787,\n",
      "                   0.09727734084740684, 0.8704715471165867,\n",
      "                   0.41997791245385685, 1.8939882246265665,\n",
      "                   1.3045581493089706, 0.016891495730507022,\n",
      "                   1.0825134171076947, 0.4498641868731396,\n",
      "                   0.5572816079716859, 1.3876728600507293,\n",
      "                   0.32349880796475544, 0.8217766436698991,\n",
      "                   1.0090612291924368, 0.6108804061099746,\n",
      "                   0.5613255178423406, 0.37127537659320947,\n",
      "                   1.5984009629117109, 0.36777644356544226,\n",
      "                   0.10050102902180082, 1.9595875273292889,\n",
      "                   0.13638968850787095, 2.409961615213128,\n",
      "                   1.2654509709938693, 1.4095631717207646,\n",
      "                   0.7338613877154541, 0.7367436583897459,\n",
      "                   1.292769300208778, 0.3706932648254344,\n",
      "                   0.36490410406377927, 0.06899666044057706,\n",
      "                   1.545214859422096, 0.9793504929693809,\n",
      "                   0.041502697857080675, 0.7798528680260858,\n",
      "                   0.13421023924469475, 0.009048873593597094,\n",
      "                   1.5413250733967796, 0.7081762391934214,\n",
      "                   0.12638613026142723, 0.357071768791901,\n",
      "                   0.6743141604040909, 0.2259392788894292,\n",
      "                   0.3272274237500469, 2.0977386874734725,\n",
      "                   0.7305281705877599, 0.8989863875863553,\n",
      "                   0.06550704501491343, 1.068685693259635,\n",
      "                   1.9066143846955315, 0.14402283216884765,\n",
      "                   1.6577085723621234, 0.08073189668722404,\n",
      "                   1.4394817632810433, 1.037123239191284,\n",
      "                   0.9829201844093749, 1.6624000510022916,\n",
      "                   1.303566423305742, 2.4103028479708426,\n",
      "                   1.3114400920352125, 1.890129412663878,\n",
      "                   0.4063787089478814, 1.2860291781478375,\n",
      "                   0.031765994651299256, 2.4526626470620867,\n",
      "                   3.414066759092168, 0.5749733634736519,\n",
      "                   0.7263296260089016, 0.7838211133659364,\n",
      "                   1.0638845276847229, 0.28616144517937714,\n",
      "                   0.44826373711890144, 1.7905958926343621,\n",
      "                   0.6743699374981261, 0.016569013717578778,\n",
      "                   0.48165795558327834, 0.3634360976782357,\n",
      "                   0.4497020308883731, 0.3915247014395856,\n",
      "                   0.48364476018068264, 0.2090900946083372,\n",
      "                   1.1639783015210483, 1.6287900070820909,\n",
      "                   0.6585984222291362, 0.17015696116536894,\n",
      "                   0.1494811337751526, 2.032314043888436,\n",
      "                   0.5806241121703316, 0.7768978820726763,\n",
      "                   1.1302567880812109, 0.06652365469410873,\n",
      "                   2.8131666623769473, 0.4726143081118227,\n",
      "                   0.34482806663880333, 0.18943698119123942,\n",
      "                   0.2594567276592774, 0.3030086654109492,\n",
      "                   0.6692427867784705, 0.681786551988037],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_reg_lambda': masked_array(data=[1.5308398716355902, 0.6412137455979741,\n",
      "                   0.7744690150873761, 0.3693778875326449,\n",
      "                   0.2093732572676367, 0.4994672686864826,\n",
      "                   0.1431609027484655, 1.8550577093101976,\n",
      "                   0.749755762105444, 0.7104684712924558,\n",
      "                   1.242473751827293, 0.7104867929478028,\n",
      "                   0.05693385697050642, 0.23741050595558524,\n",
      "                   1.09083537439143, 1.0949250730648734,\n",
      "                   0.866002642141923, 0.16242528486356345,\n",
      "                   0.367929499997219, 1.5287215297586683,\n",
      "                   1.664865434544377, 0.198389726625457,\n",
      "                   0.6650609663031101, 0.9671575927027144,\n",
      "                   1.084438871302565, 0.6276323403388302,\n",
      "                   0.34400036540755735, 0.17818645371708375,\n",
      "                   0.43489256603083704, 0.24074447218971068,\n",
      "                   0.16716667120290568, 0.7136875300367272,\n",
      "                   0.04861505651406185, 0.3243352483051537,\n",
      "                   1.9091818240761318, 0.06860521059226206,\n",
      "                   0.6844963302369299, 1.4016426556471915,\n",
      "                   1.4631176300944777, 1.0925662135902066,\n",
      "                   0.03607713990429471, 0.0772193529632216,\n",
      "                   0.740337815251582, 1.3612602380925396,\n",
      "                   1.5325703880647723, 0.14348556974312895,\n",
      "                   1.4610259147312985, 0.30902762355881386,\n",
      "                   0.2733791685907323, 0.8300846050534764,\n",
      "                   1.1530523758999318, 0.9466789316499369,\n",
      "                   1.1862250437457194, 1.1040205918547734,\n",
      "                   1.6581706168501347, 0.8545243490934442,\n",
      "                   0.9936053665419796, 0.2954853125310686,\n",
      "                   0.5488805052198771, 1.877805220292022,\n",
      "                   0.20856498449364422, 0.18040965038390702,\n",
      "                   0.13362813747929383, 1.0374463783381305,\n",
      "                   0.2197953332975685, 0.2758108127492865,\n",
      "                   0.1657341679988151, 1.6268444136108242,\n",
      "                   1.4434346120772745, 0.04628819101272837,\n",
      "                   1.2856473745045034, 1.1145118673469148,\n",
      "                   0.6608291495828621, 0.2880584635559936,\n",
      "                   0.2648895127270703, 0.10737076149593915,\n",
      "                   0.05374609903086816, 2.6606171005299926,\n",
      "                   0.03488406003521698, 3.042142313480565,\n",
      "                   1.3060417456973215, 0.06441463985569454,\n",
      "                   0.19622270587926455, 0.3551405854774576,\n",
      "                   0.44520137979850544, 1.1413716032482097,\n",
      "                   0.9101461354658199, 1.674732573908968,\n",
      "                   0.7636874727388161, 2.9568106272766648,\n",
      "                   0.7216211605740084, 0.3223144965830808,\n",
      "                   1.221407374293058, 0.14634256236615717,\n",
      "                   1.0626235164300455, 0.5174845155713836,\n",
      "                   0.5539211877194674, 1.4752228485851164,\n",
      "                   2.0278277589165485, 0.20230181745893908,\n",
      "                   0.1848511586949282, 0.19205386984876685,\n",
      "                   0.5531895095032607, 0.06067204199533175,\n",
      "                   0.324726832814272, 0.22404541742837497,\n",
      "                   0.13527925553289905, 0.6880281723611631,\n",
      "                   0.7863890290715908, 0.8824236254519411,\n",
      "                   1.8064140850878805, 0.010379754440977492,\n",
      "                   0.8712658093091448, 0.3908787163151603,\n",
      "                   0.002722568356021799, 0.29774971502279496,\n",
      "                   2.5050763428033735, 1.5784078050842445,\n",
      "                   0.747093306094617, 0.408033170174802,\n",
      "                   1.6371000939903397, 1.0734645179329103,\n",
      "                   1.1236428059848569, 0.30523293594219575,\n",
      "                   0.43984902890924205, 0.011174033472046404,\n",
      "                   1.323821141677649, 0.3427659534738321,\n",
      "                   1.0690617197230523, 0.4904380529405939,\n",
      "                   0.6119023446664243, 0.5353664635666249,\n",
      "                   0.217039668745457, 2.981907850545516,\n",
      "                   1.6615305839992767, 0.1005413973133779,\n",
      "                   0.5321975197630266, 0.35430204759082484,\n",
      "                   0.5808548632888539, 0.7340026494152305,\n",
      "                   1.5738550808607685, 0.0069075888699066355,\n",
      "                   0.6220070266686656, 0.8369999797070524,\n",
      "                   1.088641174127707, 1.0302314267442618,\n",
      "                   0.2252310230650748, 0.6958713443043448,\n",
      "                   1.196243435750288, 0.5083972985515203,\n",
      "                   0.11597114043671453, 0.9409797977081701,\n",
      "                   0.9938609340638652, 0.7165631051915888,\n",
      "                   0.20514027025482498, 0.25538320212141313,\n",
      "                   0.029782158506919044, 0.7371367546952943,\n",
      "                   0.6324110097138149, 1.420245921053014,\n",
      "                   0.41842893279404947, 0.560630802795072,\n",
      "                   0.5913810652425252, 0.47758327424981956,\n",
      "                   0.353143644617805, 0.9163761047766714,\n",
      "                   0.04283788053118467, 0.7703893410260408,\n",
      "                   0.6128382965952663, 1.1123255264990901,\n",
      "                   0.35394082644776026, 1.462919993709774,\n",
      "                   0.40281056203010535, 0.5291944168419749,\n",
      "                   1.4389661485902492, 0.4277407569978691,\n",
      "                   0.23367636020293522, 0.7271727197391178,\n",
      "                   1.0973589263697916, 2.1171022223200797,\n",
      "                   0.3998512474886332, 0.6931730491062511,\n",
      "                   0.7059952234307101, 0.022977943319227267,\n",
      "                   0.7170142416237668, 2.0673749509499113,\n",
      "                   0.8384101509007209, 0.0704391178347954,\n",
      "                   1.24520359643369, 0.9504901613147487,\n",
      "                   0.762774851945413, 0.789932502665247,\n",
      "                   0.16460689292145095, 0.37630715242820967,\n",
      "                   0.12763153958162368, 4.399592595290536,\n",
      "                   1.6735780639672646, 0.5824164985569723,\n",
      "                   0.5140272178207688, 0.2213873239043799,\n",
      "                   0.46970528721504406, 1.0378299606675463,\n",
      "                   0.14900598645159147, 2.177911052329398,\n",
      "                   0.5278455190044622, 0.3538560722519924,\n",
      "                   3.0172675092952055, 0.09734568277756701,\n",
      "                   3.825350329176527, 1.2887573657456028,\n",
      "                   0.32396044696833626, 0.06267991685873794,\n",
      "                   1.2589003976619566, 0.5033734985491038,\n",
      "                   0.9695869903502793, 2.547601588082449,\n",
      "                   0.9019895340454528, 1.2715176991823145,\n",
      "                   0.6877522832339353, 0.9939840679048441,\n",
      "                   9.082896831330372, 0.08601527348596538,\n",
      "                   1.1583771460628618, 0.20226579782719933,\n",
      "                   0.1954409434877148, 0.28478997419406377,\n",
      "                   0.16705878033872745, 3.3762061038743534,\n",
      "                   1.2963096419449256, 0.5317046353767466,\n",
      "                   0.2011071443467506, 1.1559796383213883,\n",
      "                   1.9622878505763126, 0.40124468743440195,\n",
      "                   0.12632601660470436, 0.5114618611465593,\n",
      "                   0.25465651392505473, 1.5922951394660765,\n",
      "                   0.003965400703110736, 0.7509643517682258,\n",
      "                   0.053747694886909426, 0.1759446640903645,\n",
      "                   1.107662591171944, 0.3425217938419947,\n",
      "                   4.396001821089411, 0.2315537310459832,\n",
      "                   2.4273326820025583, 0.8812086039399788,\n",
      "                   0.8819737278203663, 0.37495889430239343,\n",
      "                   0.024354731351181096, 0.6831290577786621,\n",
      "                   0.045359322042906235, 1.116783805181496,\n",
      "                   0.25225316136700543, 0.22053239474813136,\n",
      "                   0.28675745188236407, 1.850289539496446,\n",
      "                   2.0068731523490344, 0.04034280914126653,\n",
      "                   0.7858032581887832, 1.6436478475014096,\n",
      "                   0.5440752332468723, 0.9967750551004213,\n",
      "                   0.7334365750972466, 0.0669851515058275,\n",
      "                   1.8978178706444002, 0.4106787084278139,\n",
      "                   0.2857022371875775, 0.5741794399850358,\n",
      "                   1.7587446932453694, 0.002059598993947836,\n",
      "                   0.020791013334629606, 0.16170210576778277,\n",
      "                   0.001301045058197504, 1.3883290775218184,\n",
      "                   1.2856550895888998, 0.27329266033688077,\n",
      "                   0.9594612606352327, 0.6955338005952986,\n",
      "                   0.1509917886140679, 1.0098276688586596,\n",
      "                   1.668573854362538, 2.389633267354604,\n",
      "                   0.21418409965480384, 1.9670717703560194,\n",
      "                   0.16107848738732358, 0.7363336416550933,\n",
      "                   0.058278974606315884, 0.2032975979499055,\n",
      "                   1.63176894783394, 0.4264836186083766,\n",
      "                   0.2541232749001481, 0.3457835417540047,\n",
      "                   0.954496289284621, 1.156179937351307,\n",
      "                   0.43823730760234014, 2.6050213978430503,\n",
      "                   0.08425434692486451, 1.5181067415669092],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'colsample_bytree': 0.6340385251650479, 'learning_rate': 0.13721353001951353, 'num_leaves': 49, 'objective': 'poisson', 'reg_alpha': 0.43802318107538296, 'reg_lambda': 1.5308398716355902}, {'colsample_bytree': 0.11119680667187361, 'learning_rate': 0.1120419537087114, 'num_leaves': 39, 'objective': 'poisson', 'reg_alpha': 0.048487138089235444, 'reg_lambda': 0.6412137455979741}, {'colsample_bytree': 0.15586916730595152, 'learning_rate': 0.2983175872412631, 'num_leaves': 17, 'objective': 'poisson', 'reg_alpha': 0.3954342073494389, 'reg_lambda': 0.7744690150873761}, {'colsample_bytree': 0.5347198473742494, 'learning_rate': 0.10164946637519832, 'num_leaves': 58, 'objective': 'regression', 'reg_alpha': 1.2158459825844874, 'reg_lambda': 0.3693778875326449}, {'colsample_bytree': 0.28779353961201243, 'learning_rate': 0.01609676463251509, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 0.16950051749815478, 'reg_lambda': 0.2093732572676367}, {'colsample_bytree': 0.4710000144606922, 'learning_rate': 0.2191629560787668, 'num_leaves': 39, 'objective': 'poisson', 'reg_alpha': 0.6343588032506453, 'reg_lambda': 0.4994672686864826}, {'colsample_bytree': 0.9236963548145117, 'learning_rate': 0.1150873944828273, 'num_leaves': 18, 'objective': 'regression', 'reg_alpha': 2.122506215554823, 'reg_lambda': 0.1431609027484655}, {'colsample_bytree': 0.587168855975869, 'learning_rate': 0.08917670733275132, 'num_leaves': 24, 'objective': 'regression', 'reg_alpha': 0.7336897379649074, 'reg_lambda': 1.8550577093101976}, {'colsample_bytree': 0.7271037100196325, 'learning_rate': 0.18910884724124324, 'num_leaves': 51, 'objective': 'regression', 'reg_alpha': 0.8258132695968837, 'reg_lambda': 0.749755762105444}, {'colsample_bytree': 0.8755637288927931, 'learning_rate': 0.034873060784126136, 'num_leaves': 43, 'objective': 'poisson', 'reg_alpha': 0.5764120358710461, 'reg_lambda': 0.7104684712924558}, {'colsample_bytree': 0.2950481434660261, 'learning_rate': 0.004398464308455438, 'num_leaves': 27, 'objective': 'regression', 'reg_alpha': 0.37281292281281436, 'reg_lambda': 1.242473751827293}, {'colsample_bytree': 0.6943136197974605, 'learning_rate': 0.03723682634121699, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 0.30668062112157873, 'reg_lambda': 0.7104867929478028}, {'colsample_bytree': 0.6625932914017024, 'learning_rate': 0.013027152761594408, 'num_leaves': 30, 'objective': 'poisson', 'reg_alpha': 0.06771574343825915, 'reg_lambda': 0.05693385697050642}, {'colsample_bytree': 0.43488097836414685, 'learning_rate': 0.06625796106846611, 'num_leaves': 19, 'objective': 'regression', 'reg_alpha': 1.5979050888865756, 'reg_lambda': 0.23741050595558524}, {'colsample_bytree': 0.8370702847105156, 'learning_rate': 0.16393320243791407, 'num_leaves': 51, 'objective': 'regression', 'reg_alpha': 1.1443076702514239, 'reg_lambda': 1.09083537439143}, {'colsample_bytree': 0.17296526046876237, 'learning_rate': 0.08787995956808402, 'num_leaves': 18, 'objective': 'regression', 'reg_alpha': 0.370894917252928, 'reg_lambda': 1.0949250730648734}, {'colsample_bytree': 0.7680989486072965, 'learning_rate': 0.10761030207262089, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 1.241542060791901, 'reg_lambda': 0.866002642141923}, {'colsample_bytree': 0.37455044596508513, 'learning_rate': 0.12750316021829625, 'num_leaves': 17, 'objective': 'poisson', 'reg_alpha': 1.8960224830956147, 'reg_lambda': 0.16242528486356345}, {'colsample_bytree': 0.8841942396289215, 'learning_rate': 0.11386962309689633, 'num_leaves': 48, 'objective': 'regression', 'reg_alpha': 1.6476516747993188, 'reg_lambda': 0.367929499997219}, {'colsample_bytree': 0.19932893363237125, 'learning_rate': 0.10126868369933915, 'num_leaves': 21, 'objective': 'poisson', 'reg_alpha': 0.605628663307387, 'reg_lambda': 1.5287215297586683}, {'colsample_bytree': 0.5620446186966679, 'learning_rate': 0.19093364391415182, 'num_leaves': 17, 'objective': 'regression', 'reg_alpha': 0.2429480859030139, 'reg_lambda': 1.664865434544377}, {'colsample_bytree': 0.8036647423646476, 'learning_rate': 0.03373131563022606, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 2.573240338923107, 'reg_lambda': 0.198389726625457}, {'colsample_bytree': 0.22988135687243577, 'learning_rate': 0.18689508877328131, 'num_leaves': 35, 'objective': 'regression', 'reg_alpha': 1.454635127197847, 'reg_lambda': 0.6650609663031101}, {'colsample_bytree': 0.471107825903025, 'learning_rate': 0.024305850003930346, 'num_leaves': 31, 'objective': 'poisson', 'reg_alpha': 2.0301317467345026, 'reg_lambda': 0.9671575927027144}, {'colsample_bytree': 0.4945203977526864, 'learning_rate': 0.034134626185190246, 'num_leaves': 12, 'objective': 'poisson', 'reg_alpha': 0.7747426521377447, 'reg_lambda': 1.084438871302565}, {'colsample_bytree': 0.5115227495097804, 'learning_rate': 0.15224443286006745, 'num_leaves': 33, 'objective': 'regression', 'reg_alpha': 0.06920113383622226, 'reg_lambda': 0.6276323403388302}, {'colsample_bytree': 0.7773587882107825, 'learning_rate': 0.20119754232529377, 'num_leaves': 23, 'objective': 'poisson', 'reg_alpha': 2.4697005100735727, 'reg_lambda': 0.34400036540755735}, {'colsample_bytree': 0.9609633643023151, 'learning_rate': 0.08358849899242443, 'num_leaves': 27, 'objective': 'poisson', 'reg_alpha': 0.9929988413028956, 'reg_lambda': 0.17818645371708375}, {'colsample_bytree': 0.49581171971899696, 'learning_rate': 0.07723730330196749, 'num_leaves': 34, 'objective': 'regression', 'reg_alpha': 0.10887987924169945, 'reg_lambda': 0.43489256603083704}, {'colsample_bytree': 0.31397797861416016, 'learning_rate': 0.20898988949325453, 'num_leaves': 35, 'objective': 'regression', 'reg_alpha': 0.18621245553570853, 'reg_lambda': 0.24074447218971068}, {'colsample_bytree': 0.3923909398385672, 'learning_rate': 0.0006283745734353392, 'num_leaves': 53, 'objective': 'poisson', 'reg_alpha': 0.21891625631372205, 'reg_lambda': 0.16716667120290568}, {'colsample_bytree': 0.2277169936298066, 'learning_rate': 0.005564300385676136, 'num_leaves': 44, 'objective': 'regression', 'reg_alpha': 0.7216859496784237, 'reg_lambda': 0.7136875300367272}, {'colsample_bytree': 0.8420240867204978, 'learning_rate': 0.05700963458097962, 'num_leaves': 30, 'objective': 'poisson', 'reg_alpha': 0.6981828821055034, 'reg_lambda': 0.04861505651406185}, {'colsample_bytree': 0.3749225165218426, 'learning_rate': 0.2861538345128047, 'num_leaves': 58, 'objective': 'poisson', 'reg_alpha': 0.19460814545218844, 'reg_lambda': 0.3243352483051537}, {'colsample_bytree': 0.4761685096564008, 'learning_rate': 0.1173173677005946, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 1.6774770543519928, 'reg_lambda': 1.9091818240761318}, {'colsample_bytree': 0.18203535125557757, 'learning_rate': 0.040431862591854335, 'num_leaves': 35, 'objective': 'poisson', 'reg_alpha': 0.17518971429550403, 'reg_lambda': 0.06860521059226206}, {'colsample_bytree': 0.8492066142072107, 'learning_rate': 0.05335521043939724, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 0.9742113191447452, 'reg_lambda': 0.6844963302369299}, {'colsample_bytree': 0.5589313955192885, 'learning_rate': 0.1300330146822176, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 0.7155147118224264, 'reg_lambda': 1.4016426556471915}, {'colsample_bytree': 0.6636431741790647, 'learning_rate': 0.02204870971282969, 'num_leaves': 15, 'objective': 'poisson', 'reg_alpha': 0.7529221655560803, 'reg_lambda': 1.4631176300944777}, {'colsample_bytree': 0.3469052316223026, 'learning_rate': 0.021547029879433376, 'num_leaves': 58, 'objective': 'poisson', 'reg_alpha': 0.22979003495391523, 'reg_lambda': 1.0925662135902066}, {'colsample_bytree': 0.9441123898657012, 'learning_rate': 0.13419360131779975, 'num_leaves': 31, 'objective': 'regression', 'reg_alpha': 0.513623392696352, 'reg_lambda': 0.03607713990429471}, {'colsample_bytree': 0.25182035145294235, 'learning_rate': 0.021452932411615062, 'num_leaves': 18, 'objective': 'poisson', 'reg_alpha': 0.19889239476433715, 'reg_lambda': 0.0772193529632216}, {'colsample_bytree': 0.21075654120295892, 'learning_rate': 0.013788964965471759, 'num_leaves': 49, 'objective': 'regression', 'reg_alpha': 0.05758116251676125, 'reg_lambda': 0.740337815251582}, {'colsample_bytree': 0.9323195512888698, 'learning_rate': 0.1375429719431471, 'num_leaves': 27, 'objective': 'poisson', 'reg_alpha': 0.34770755434380496, 'reg_lambda': 1.3612602380925396}, {'colsample_bytree': 0.5023788127020643, 'learning_rate': 0.007589705904968035, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 4.586403037533275, 'reg_lambda': 1.5325703880647723}, {'colsample_bytree': 0.3154044293679312, 'learning_rate': 0.0977987504824806, 'num_leaves': 56, 'objective': 'regression', 'reg_alpha': 3.411869641710405, 'reg_lambda': 0.14348556974312895}, {'colsample_bytree': 0.5221133293854752, 'learning_rate': 0.06562687413111504, 'num_leaves': 23, 'objective': 'regression', 'reg_alpha': 1.1220785000688507, 'reg_lambda': 1.4610259147312985}, {'colsample_bytree': 0.7022391579532242, 'learning_rate': 0.2739214709362535, 'num_leaves': 21, 'objective': 'regression', 'reg_alpha': 0.4066984032074417, 'reg_lambda': 0.30902762355881386}, {'colsample_bytree': 0.6259570635539394, 'learning_rate': 0.18192919881000247, 'num_leaves': 37, 'objective': 'regression', 'reg_alpha': 2.5635655849094863, 'reg_lambda': 0.2733791685907323}, {'colsample_bytree': 0.9417974107836565, 'learning_rate': 0.0020970943895581486, 'num_leaves': 48, 'objective': 'regression', 'reg_alpha': 0.7803534607571271, 'reg_lambda': 0.8300846050534764}, {'colsample_bytree': 0.35640514305524795, 'learning_rate': 0.05775443774336092, 'num_leaves': 33, 'objective': 'poisson', 'reg_alpha': 0.30974501670387095, 'reg_lambda': 1.1530523758999318}, {'colsample_bytree': 0.543115978203606, 'learning_rate': 0.08676451894947784, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 0.5493771108593697, 'reg_lambda': 0.9466789316499369}, {'colsample_bytree': 0.9659980574273919, 'learning_rate': 0.03531551476485263, 'num_leaves': 52, 'objective': 'regression', 'reg_alpha': 0.5867862660736856, 'reg_lambda': 1.1862250437457194}, {'colsample_bytree': 0.9427275454713274, 'learning_rate': 0.031467150704129115, 'num_leaves': 40, 'objective': 'poisson', 'reg_alpha': 0.9754504342542487, 'reg_lambda': 1.1040205918547734}, {'colsample_bytree': 0.7680835988692413, 'learning_rate': 0.07238452210296664, 'num_leaves': 49, 'objective': 'regression', 'reg_alpha': 2.548679130544533, 'reg_lambda': 1.6581706168501347}, {'colsample_bytree': 0.6458761400685762, 'learning_rate': 0.1730648150252108, 'num_leaves': 36, 'objective': 'regression', 'reg_alpha': 0.8196164817177749, 'reg_lambda': 0.8545243490934442}, {'colsample_bytree': 0.21439137138160427, 'learning_rate': 0.036916855320430625, 'num_leaves': 29, 'objective': 'regression', 'reg_alpha': 0.13448638622772957, 'reg_lambda': 0.9936053665419796}, {'colsample_bytree': 0.11282339406606566, 'learning_rate': 0.3103731373665605, 'num_leaves': 30, 'objective': 'regression', 'reg_alpha': 1.3557500285625643, 'reg_lambda': 0.2954853125310686}, {'colsample_bytree': 0.9694113343097239, 'learning_rate': 0.1310434557350093, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.0874873906979539, 'reg_lambda': 0.5488805052198771}, {'colsample_bytree': 0.9570237867132961, 'learning_rate': 0.06808928776723219, 'num_leaves': 23, 'objective': 'regression', 'reg_alpha': 1.420496320868553, 'reg_lambda': 1.877805220292022}, {'colsample_bytree': 0.7295081049511466, 'learning_rate': 0.011010327538498663, 'num_leaves': 52, 'objective': 'regression', 'reg_alpha': 0.6257162041684075, 'reg_lambda': 0.20856498449364422}, {'colsample_bytree': 0.18419529965011805, 'learning_rate': 0.018818657262798785, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.09881785655139512, 'reg_lambda': 0.18040965038390702}, {'colsample_bytree': 0.3182984726732941, 'learning_rate': 0.033913113433316544, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 1.2260021102455307, 'reg_lambda': 0.13362813747929383}, {'colsample_bytree': 0.18197495308868156, 'learning_rate': 0.052477611269077976, 'num_leaves': 58, 'objective': 'poisson', 'reg_alpha': 0.7419666860269557, 'reg_lambda': 1.0374463783381305}, {'colsample_bytree': 0.5789555821160584, 'learning_rate': 0.0096445468087862, 'num_leaves': 58, 'objective': 'regression', 'reg_alpha': 1.5850573794915421, 'reg_lambda': 0.2197953332975685}, {'colsample_bytree': 0.9050183203265487, 'learning_rate': 0.38494959031066195, 'num_leaves': 23, 'objective': 'poisson', 'reg_alpha': 3.4701955251974033, 'reg_lambda': 0.2758108127492865}, {'colsample_bytree': 0.666293429218502, 'learning_rate': 0.09003491211900631, 'num_leaves': 30, 'objective': 'regression', 'reg_alpha': 0.0002713721231523572, 'reg_lambda': 0.1657341679988151}, {'colsample_bytree': 0.5154516314699359, 'learning_rate': 0.038552334775197976, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 1.1561145400002688, 'reg_lambda': 1.6268444136108242}, {'colsample_bytree': 0.8585064974515718, 'learning_rate': 0.009401710541715205, 'num_leaves': 43, 'objective': 'poisson', 'reg_alpha': 1.9513085162196246, 'reg_lambda': 1.4434346120772745}, {'colsample_bytree': 0.8270136477631191, 'learning_rate': 0.054142832211196194, 'num_leaves': 54, 'objective': 'poisson', 'reg_alpha': 5.243228754470758, 'reg_lambda': 0.04628819101272837}, {'colsample_bytree': 0.29779816579183216, 'learning_rate': 0.020079400653059146, 'num_leaves': 16, 'objective': 'regression', 'reg_alpha': 0.05210325406949956, 'reg_lambda': 1.2856473745045034}, {'colsample_bytree': 0.8953063947319679, 'learning_rate': 0.02005189314158819, 'num_leaves': 57, 'objective': 'regression', 'reg_alpha': 2.0926617930631433, 'reg_lambda': 1.1145118673469148}, {'colsample_bytree': 0.9959257717919823, 'learning_rate': 0.21578778827840575, 'num_leaves': 17, 'objective': 'poisson', 'reg_alpha': 1.1136860646857563, 'reg_lambda': 0.6608291495828621}, {'colsample_bytree': 0.8271962933089692, 'learning_rate': 0.1595141180305381, 'num_leaves': 21, 'objective': 'poisson', 'reg_alpha': 0.055170535951142664, 'reg_lambda': 0.2880584635559936}, {'colsample_bytree': 0.7106899422598779, 'learning_rate': 0.14659124218958608, 'num_leaves': 51, 'objective': 'poisson', 'reg_alpha': 1.7612283411688938, 'reg_lambda': 0.2648895127270703}, {'colsample_bytree': 0.7435764232140434, 'learning_rate': 0.0962120802883251, 'num_leaves': 49, 'objective': 'poisson', 'reg_alpha': 1.1887857553591914, 'reg_lambda': 0.10737076149593915}, {'colsample_bytree': 0.9148979049342736, 'learning_rate': 0.20965375871393088, 'num_leaves': 56, 'objective': 'poisson', 'reg_alpha': 0.556405508868846, 'reg_lambda': 0.05374609903086816}, {'colsample_bytree': 0.22402313452669434, 'learning_rate': 0.09837419407892008, 'num_leaves': 50, 'objective': 'poisson', 'reg_alpha': 0.07428299646942262, 'reg_lambda': 2.6606171005299926}, {'colsample_bytree': 0.9565618407433233, 'learning_rate': 0.0701533999318326, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 1.5203015023702902, 'reg_lambda': 0.03488406003521698}, {'colsample_bytree': 0.7597729381192027, 'learning_rate': 0.09917727494194369, 'num_leaves': 13, 'objective': 'poisson', 'reg_alpha': 4.522598020250046, 'reg_lambda': 3.042142313480565}, {'colsample_bytree': 0.9898598974561045, 'learning_rate': 0.08477055904917222, 'num_leaves': 22, 'objective': 'poisson', 'reg_alpha': 1.1416400002662785, 'reg_lambda': 1.3060417456973215}, {'colsample_bytree': 0.452095962988177, 'learning_rate': 0.15379387230964847, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.09844407737366118, 'reg_lambda': 0.06441463985569454}, {'colsample_bytree': 0.6350397662571905, 'learning_rate': 0.051624484796081005, 'num_leaves': 21, 'objective': 'poisson', 'reg_alpha': 0.6147389667289054, 'reg_lambda': 0.19622270587926455}, {'colsample_bytree': 0.8859279110283729, 'learning_rate': 0.14761031721794476, 'num_leaves': 55, 'objective': 'poisson', 'reg_alpha': 2.6503485771255644, 'reg_lambda': 0.3551405854774576}, {'colsample_bytree': 0.656571853114962, 'learning_rate': 0.031262936896216086, 'num_leaves': 33, 'objective': 'poisson', 'reg_alpha': 3.3504316238851093, 'reg_lambda': 0.44520137979850544}, {'colsample_bytree': 0.7838939383311693, 'learning_rate': 0.20341438278618182, 'num_leaves': 40, 'objective': 'poisson', 'reg_alpha': 1.380846418956336, 'reg_lambda': 1.1413716032482097}, {'colsample_bytree': 0.4611449201481771, 'learning_rate': 0.02080498129883168, 'num_leaves': 35, 'objective': 'poisson', 'reg_alpha': 0.7435756159291053, 'reg_lambda': 0.9101461354658199}, {'colsample_bytree': 0.772819441791403, 'learning_rate': 0.07289345473905243, 'num_leaves': 26, 'objective': 'regression', 'reg_alpha': 1.6801776879657317, 'reg_lambda': 1.674732573908968}, {'colsample_bytree': 0.9670362321022685, 'learning_rate': 0.04880243712542856, 'num_leaves': 49, 'objective': 'regression', 'reg_alpha': 0.24580012402947657, 'reg_lambda': 0.7636874727388161}, {'colsample_bytree': 0.8530255069959972, 'learning_rate': 0.15652319807376272, 'num_leaves': 41, 'objective': 'poisson', 'reg_alpha': 0.02368577946156917, 'reg_lambda': 2.9568106272766648}, {'colsample_bytree': 0.632787244269748, 'learning_rate': 0.0038904308262780285, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 0.430341897643021, 'reg_lambda': 0.7216211605740084}, {'colsample_bytree': 0.7533968337306085, 'learning_rate': 0.024087143514587097, 'num_leaves': 34, 'objective': 'regression', 'reg_alpha': 0.20742549623079165, 'reg_lambda': 0.3223144965830808}, {'colsample_bytree': 0.7844025999870516, 'learning_rate': 0.09142938134452808, 'num_leaves': 26, 'objective': 'regression', 'reg_alpha': 0.33467895238225104, 'reg_lambda': 1.221407374293058}, {'colsample_bytree': 0.5982831638871072, 'learning_rate': 0.07314329367541503, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 0.3758830898145239, 'reg_lambda': 0.14634256236615717}, {'colsample_bytree': 0.6757649580926302, 'learning_rate': 0.3725910676406671, 'num_leaves': 46, 'objective': 'poisson', 'reg_alpha': 4.705373381691776, 'reg_lambda': 1.0626235164300455}, {'colsample_bytree': 0.9008608214212219, 'learning_rate': 0.24433208973784248, 'num_leaves': 52, 'objective': 'regression', 'reg_alpha': 0.2922416279154702, 'reg_lambda': 0.5174845155713836}, {'colsample_bytree': 0.5431036713676786, 'learning_rate': 0.22816136052793334, 'num_leaves': 17, 'objective': 'regression', 'reg_alpha': 0.33916404869803773, 'reg_lambda': 0.5539211877194674}, {'colsample_bytree': 0.15299465647791388, 'learning_rate': 0.0714237147792365, 'num_leaves': 32, 'objective': 'poisson', 'reg_alpha': 2.332993636161555, 'reg_lambda': 1.4752228485851164}, {'colsample_bytree': 0.2000389381749706, 'learning_rate': 0.15198220066353338, 'num_leaves': 30, 'objective': 'poisson', 'reg_alpha': 0.3416441594747109, 'reg_lambda': 2.0278277589165485}, {'colsample_bytree': 0.4646400763664966, 'learning_rate': 0.42463513503131867, 'num_leaves': 38, 'objective': 'regression', 'reg_alpha': 1.1271718030795692, 'reg_lambda': 0.20230181745893908}, {'colsample_bytree': 0.6680257636956435, 'learning_rate': 0.15512315938775093, 'num_leaves': 34, 'objective': 'poisson', 'reg_alpha': 0.28191064957070633, 'reg_lambda': 0.1848511586949282}, {'colsample_bytree': 0.33618800161969575, 'learning_rate': 0.06981729419763069, 'num_leaves': 22, 'objective': 'poisson', 'reg_alpha': 0.712380727878081, 'reg_lambda': 0.19205386984876685}, {'colsample_bytree': 0.38867515290145227, 'learning_rate': 0.07915588762718129, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.4114921876681898, 'reg_lambda': 0.5531895095032607}, {'colsample_bytree': 0.3653231678872124, 'learning_rate': 0.46861073183344204, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 0.18440521780105915, 'reg_lambda': 0.06067204199533175}, {'colsample_bytree': 0.3535328016018561, 'learning_rate': 0.03697261106616251, 'num_leaves': 59, 'objective': 'poisson', 'reg_alpha': 0.9005700177292141, 'reg_lambda': 0.324726832814272}, {'colsample_bytree': 0.24893718402464823, 'learning_rate': 0.018508738913997572, 'num_leaves': 49, 'objective': 'poisson', 'reg_alpha': 0.6747931486753183, 'reg_lambda': 0.22404541742837497}, {'colsample_bytree': 0.23709040866227865, 'learning_rate': 0.09193169938578101, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 0.07817610044433063, 'reg_lambda': 0.13527925553289905}, {'colsample_bytree': 0.5196271505895719, 'learning_rate': 0.1080642860044764, 'num_leaves': 32, 'objective': 'regression', 'reg_alpha': 0.5059894906149927, 'reg_lambda': 0.6880281723611631}, {'colsample_bytree': 0.8417077273421989, 'learning_rate': 0.08466316296417803, 'num_leaves': 24, 'objective': 'poisson', 'reg_alpha': 0.1270043097778588, 'reg_lambda': 0.7863890290715908}, {'colsample_bytree': 0.6548375637007657, 'learning_rate': 0.19440041723943058, 'num_leaves': 33, 'objective': 'poisson', 'reg_alpha': 0.5755320805049392, 'reg_lambda': 0.8824236254519411}, {'colsample_bytree': 0.3572648059476131, 'learning_rate': 0.07137271132888452, 'num_leaves': 58, 'objective': 'poisson', 'reg_alpha': 1.2697597586477538, 'reg_lambda': 1.8064140850878805}, {'colsample_bytree': 0.33160720986933184, 'learning_rate': 0.014554583797159274, 'num_leaves': 32, 'objective': 'regression', 'reg_alpha': 1.5894419242373896, 'reg_lambda': 0.010379754440977492}, {'colsample_bytree': 0.6491038287486129, 'learning_rate': 0.04287528276562599, 'num_leaves': 28, 'objective': 'regression', 'reg_alpha': 3.359229767338584, 'reg_lambda': 0.8712658093091448}, {'colsample_bytree': 0.178164869484593, 'learning_rate': 0.13479323578340255, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 0.6736711849323584, 'reg_lambda': 0.3908787163151603}, {'colsample_bytree': 0.23653792442642782, 'learning_rate': 0.05841722933685242, 'num_leaves': 17, 'objective': 'regression', 'reg_alpha': 0.42897002233064147, 'reg_lambda': 0.002722568356021799}, {'colsample_bytree': 0.686000000700596, 'learning_rate': 0.05149915731091353, 'num_leaves': 42, 'objective': 'regression', 'reg_alpha': 0.30872740715279184, 'reg_lambda': 0.29774971502279496}, {'colsample_bytree': 0.4704828566553797, 'learning_rate': 0.027088420862536558, 'num_leaves': 38, 'objective': 'poisson', 'reg_alpha': 0.5247563711717522, 'reg_lambda': 2.5050763428033735}, {'colsample_bytree': 0.12329462792232826, 'learning_rate': 0.07267832091695267, 'num_leaves': 49, 'objective': 'poisson', 'reg_alpha': 0.019770831156341928, 'reg_lambda': 1.5784078050842445}, {'colsample_bytree': 0.198144098491158, 'learning_rate': 0.20578117206295488, 'num_leaves': 14, 'objective': 'regression', 'reg_alpha': 0.15068402304544562, 'reg_lambda': 0.747093306094617}, {'colsample_bytree': 0.5091533154451762, 'learning_rate': 0.06415673917086971, 'num_leaves': 42, 'objective': 'regression', 'reg_alpha': 0.2312273010420005, 'reg_lambda': 0.408033170174802}, {'colsample_bytree': 0.6507590598445704, 'learning_rate': 0.012760782136666152, 'num_leaves': 12, 'objective': 'poisson', 'reg_alpha': 0.12991649198891295, 'reg_lambda': 1.6371000939903397}, {'colsample_bytree': 0.3658211747638409, 'learning_rate': 0.06967256258483989, 'num_leaves': 31, 'objective': 'regression', 'reg_alpha': 0.8910039781497688, 'reg_lambda': 1.0734645179329103}, {'colsample_bytree': 0.16810155594708398, 'learning_rate': 0.06078013384265866, 'num_leaves': 51, 'objective': 'regression', 'reg_alpha': 1.5630636841010543, 'reg_lambda': 1.1236428059848569}, {'colsample_bytree': 0.8322766832913966, 'learning_rate': 0.16321774570797998, 'num_leaves': 31, 'objective': 'poisson', 'reg_alpha': 0.4009041834635661, 'reg_lambda': 0.30523293594219575}, {'colsample_bytree': 0.10576550925523748, 'learning_rate': 0.002262565128818962, 'num_leaves': 59, 'objective': 'regression', 'reg_alpha': 0.44218030559043164, 'reg_lambda': 0.43984902890924205}, {'colsample_bytree': 0.45601931439729515, 'learning_rate': 0.19924965862634203, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 0.602389070288156, 'reg_lambda': 0.011174033472046404}, {'colsample_bytree': 0.23897084490267767, 'learning_rate': 0.22290195690879944, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 2.261714383391091, 'reg_lambda': 1.323821141677649}, {'colsample_bytree': 0.45262852698058087, 'learning_rate': 0.08825712997685436, 'num_leaves': 42, 'objective': 'poisson', 'reg_alpha': 0.09443393064125023, 'reg_lambda': 0.3427659534738321}, {'colsample_bytree': 0.6255541901624335, 'learning_rate': 0.022410048517253797, 'num_leaves': 22, 'objective': 'poisson', 'reg_alpha': 0.4492603302066354, 'reg_lambda': 1.0690617197230523}, {'colsample_bytree': 0.35634344792715855, 'learning_rate': 0.017310605174929015, 'num_leaves': 19, 'objective': 'regression', 'reg_alpha': 0.7211043011031748, 'reg_lambda': 0.4904380529405939}, {'colsample_bytree': 0.24998594295299367, 'learning_rate': 0.014532289791370005, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 0.5621605933899536, 'reg_lambda': 0.6119023446664243}, {'colsample_bytree': 0.7669398682435363, 'learning_rate': 0.09671771752823162, 'num_leaves': 13, 'objective': 'regression', 'reg_alpha': 0.838790687367086, 'reg_lambda': 0.5353664635666249}, {'colsample_bytree': 0.897150935571347, 'learning_rate': 0.19735472664584328, 'num_leaves': 27, 'objective': 'poisson', 'reg_alpha': 0.6375075373063976, 'reg_lambda': 0.217039668745457}, {'colsample_bytree': 0.31491827784621806, 'learning_rate': 0.021032602728267114, 'num_leaves': 23, 'objective': 'poisson', 'reg_alpha': 0.7433185759589663, 'reg_lambda': 2.981907850545516}, {'colsample_bytree': 0.6546969491572012, 'learning_rate': 0.030183866524842763, 'num_leaves': 54, 'objective': 'poisson', 'reg_alpha': 0.5626257827382358, 'reg_lambda': 1.6615305839992767}, {'colsample_bytree': 0.3663858250595775, 'learning_rate': 0.08549874571613028, 'num_leaves': 32, 'objective': 'regression', 'reg_alpha': 0.8400651303422296, 'reg_lambda': 0.1005413973133779}, {'colsample_bytree': 0.11089808919331559, 'learning_rate': 0.0436041264529394, 'num_leaves': 19, 'objective': 'regression', 'reg_alpha': 1.9642079805582973, 'reg_lambda': 0.5321975197630266}, {'colsample_bytree': 0.11071520271458847, 'learning_rate': 0.016436791638869127, 'num_leaves': 31, 'objective': 'poisson', 'reg_alpha': 0.3619195937727834, 'reg_lambda': 0.35430204759082484}, {'colsample_bytree': 0.33499836040104725, 'learning_rate': 0.016097346669252374, 'num_leaves': 34, 'objective': 'regression', 'reg_alpha': 0.13130620385714134, 'reg_lambda': 0.5808548632888539}, {'colsample_bytree': 0.25073574364293616, 'learning_rate': 0.03327556328622878, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 0.651678482971365, 'reg_lambda': 0.7340026494152305}, {'colsample_bytree': 0.44784407702950957, 'learning_rate': 0.003933507468437052, 'num_leaves': 18, 'objective': 'poisson', 'reg_alpha': 0.10193601241623848, 'reg_lambda': 1.5738550808607685}, {'colsample_bytree': 0.9403051899627942, 'learning_rate': 0.02553222046609372, 'num_leaves': 56, 'objective': 'poisson', 'reg_alpha': 3.0264682262543077, 'reg_lambda': 0.0069075888699066355}, {'colsample_bytree': 0.6088418415713118, 'learning_rate': 0.060503568445079314, 'num_leaves': 24, 'objective': 'poisson', 'reg_alpha': 6.234794866586649, 'reg_lambda': 0.6220070266686656}, {'colsample_bytree': 0.1752838268154666, 'learning_rate': 0.057393617194400615, 'num_leaves': 56, 'objective': 'poisson', 'reg_alpha': 0.13885501293231126, 'reg_lambda': 0.8369999797070524}, {'colsample_bytree': 0.6419914590110202, 'learning_rate': 0.28705191020813964, 'num_leaves': 31, 'objective': 'poisson', 'reg_alpha': 0.20442753704033587, 'reg_lambda': 1.088641174127707}, {'colsample_bytree': 0.30714635295584103, 'learning_rate': 0.009153929892893639, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 1.951704978895264, 'reg_lambda': 1.0302314267442618}, {'colsample_bytree': 0.6450582725752908, 'learning_rate': 0.1023211084757759, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 0.26009118053587915, 'reg_lambda': 0.2252310230650748}, {'colsample_bytree': 0.6949935144602688, 'learning_rate': 0.2657116015051434, 'num_leaves': 43, 'objective': 'regression', 'reg_alpha': 0.19998217585232095, 'reg_lambda': 0.6958713443043448}, {'colsample_bytree': 0.35717067639812383, 'learning_rate': 0.3143509323759226, 'num_leaves': 28, 'objective': 'regression', 'reg_alpha': 1.434583575973427, 'reg_lambda': 1.196243435750288}, {'colsample_bytree': 0.16689899827891774, 'learning_rate': 0.2999059901259952, 'num_leaves': 51, 'objective': 'poisson', 'reg_alpha': 1.5191643192536244, 'reg_lambda': 0.5083972985515203}, {'colsample_bytree': 0.9906718772681412, 'learning_rate': 0.1430203710651645, 'num_leaves': 59, 'objective': 'regression', 'reg_alpha': 0.4125867919824576, 'reg_lambda': 0.11597114043671453}, {'colsample_bytree': 0.5976394866488967, 'learning_rate': 0.05098680946369856, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 1.0954095594954478, 'reg_lambda': 0.9409797977081701}, {'colsample_bytree': 0.1603396972687014, 'learning_rate': 0.09969219366211418, 'num_leaves': 56, 'objective': 'regression', 'reg_alpha': 1.3657203868947152, 'reg_lambda': 0.9938609340638652}, {'colsample_bytree': 0.8108848366032662, 'learning_rate': 0.27306664090667104, 'num_leaves': 48, 'objective': 'poisson', 'reg_alpha': 1.304029817641542, 'reg_lambda': 0.7165631051915888}, {'colsample_bytree': 0.1766518064770613, 'learning_rate': 0.04509491318806991, 'num_leaves': 49, 'objective': 'poisson', 'reg_alpha': 0.2090799375503098, 'reg_lambda': 0.20514027025482498}, {'colsample_bytree': 0.5757462412328647, 'learning_rate': 0.010233295383476905, 'num_leaves': 29, 'objective': 'poisson', 'reg_alpha': 0.28693480961820117, 'reg_lambda': 0.25538320212141313}, {'colsample_bytree': 0.9469306559375079, 'learning_rate': 0.08764228062115931, 'num_leaves': 55, 'objective': 'poisson', 'reg_alpha': 0.44623011896783465, 'reg_lambda': 0.029782158506919044}, {'colsample_bytree': 0.9961324990629057, 'learning_rate': 0.10849722722061672, 'num_leaves': 12, 'objective': 'poisson', 'reg_alpha': 0.3706805412923388, 'reg_lambda': 0.7371367546952943}, {'colsample_bytree': 0.8531529257244939, 'learning_rate': 0.07869456720077828, 'num_leaves': 36, 'objective': 'regression', 'reg_alpha': 3.6030650092014427, 'reg_lambda': 0.6324110097138149}, {'colsample_bytree': 0.5077974236246021, 'learning_rate': 0.16248728123245748, 'num_leaves': 46, 'objective': 'poisson', 'reg_alpha': 0.3561183216280932, 'reg_lambda': 1.420245921053014}, {'colsample_bytree': 0.5273175154715097, 'learning_rate': 0.0666711222880479, 'num_leaves': 57, 'objective': 'regression', 'reg_alpha': 1.2624171627733656, 'reg_lambda': 0.41842893279404947}, {'colsample_bytree': 0.3386656358824352, 'learning_rate': 0.12393140088267374, 'num_leaves': 53, 'objective': 'poisson', 'reg_alpha': 0.0009221373459273397, 'reg_lambda': 0.560630802795072}, {'colsample_bytree': 0.4844624724869392, 'learning_rate': 0.003750560069163047, 'num_leaves': 29, 'objective': 'poisson', 'reg_alpha': 0.2482604864613469, 'reg_lambda': 0.5913810652425252}, {'colsample_bytree': 0.7781267850834566, 'learning_rate': 0.0677957507816428, 'num_leaves': 36, 'objective': 'regression', 'reg_alpha': 0.4526837251285327, 'reg_lambda': 0.47758327424981956}, {'colsample_bytree': 0.44154846836721284, 'learning_rate': 0.07337494051280784, 'num_leaves': 32, 'objective': 'regression', 'reg_alpha': 2.3757904499640947, 'reg_lambda': 0.353143644617805}, {'colsample_bytree': 0.9982627786388367, 'learning_rate': 0.1571734593649373, 'num_leaves': 20, 'objective': 'poisson', 'reg_alpha': 0.8787289061802923, 'reg_lambda': 0.9163761047766714}, {'colsample_bytree': 0.6531245950413587, 'learning_rate': 0.01703523012369829, 'num_leaves': 54, 'objective': 'poisson', 'reg_alpha': 4.1821606025086275, 'reg_lambda': 0.04283788053118467}, {'colsample_bytree': 0.9363606284403434, 'learning_rate': 0.16188564964555138, 'num_leaves': 22, 'objective': 'poisson', 'reg_alpha': 1.2918874900357864, 'reg_lambda': 0.7703893410260408}, {'colsample_bytree': 0.34846602143635386, 'learning_rate': 0.18738336322827437, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 0.4078227923082333, 'reg_lambda': 0.6128382965952663}, {'colsample_bytree': 0.23907292016373563, 'learning_rate': 0.054018739878122696, 'num_leaves': 16, 'objective': 'poisson', 'reg_alpha': 3.6072348298973953, 'reg_lambda': 1.1123255264990901}, {'colsample_bytree': 0.9503058474119538, 'learning_rate': 0.14932698673275538, 'num_leaves': 13, 'objective': 'regression', 'reg_alpha': 2.93965392647211, 'reg_lambda': 0.35394082644776026}, {'colsample_bytree': 0.24270561897952297, 'learning_rate': 0.049057409483257236, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 2.6044743937190287, 'reg_lambda': 1.462919993709774}, {'colsample_bytree': 0.8425559461407449, 'learning_rate': 0.04357816761647343, 'num_leaves': 38, 'objective': 'regression', 'reg_alpha': 2.2955857453991335, 'reg_lambda': 0.40281056203010535}, {'colsample_bytree': 0.9539588768000146, 'learning_rate': 0.10597535318232201, 'num_leaves': 13, 'objective': 'poisson', 'reg_alpha': 0.37423892762851574, 'reg_lambda': 0.5291944168419749}, {'colsample_bytree': 0.4073109425564988, 'learning_rate': 0.08371030304184437, 'num_leaves': 27, 'objective': 'regression', 'reg_alpha': 0.45179514337660204, 'reg_lambda': 1.4389661485902492}, {'colsample_bytree': 0.36168139683410905, 'learning_rate': 1.0399361785529096e-05, 'num_leaves': 45, 'objective': 'poisson', 'reg_alpha': 0.6484197440506422, 'reg_lambda': 0.4277407569978691}, {'colsample_bytree': 0.5231960085145012, 'learning_rate': 0.013403328230611956, 'num_leaves': 50, 'objective': 'regression', 'reg_alpha': 1.3429371403317714, 'reg_lambda': 0.23367636020293522}, {'colsample_bytree': 0.7613917683444177, 'learning_rate': 0.0006038977751746933, 'num_leaves': 40, 'objective': 'poisson', 'reg_alpha': 0.41994521074711594, 'reg_lambda': 0.7271727197391178}, {'colsample_bytree': 0.2919273412558355, 'learning_rate': 0.05410936009211364, 'num_leaves': 38, 'objective': 'poisson', 'reg_alpha': 1.7944334461077311, 'reg_lambda': 1.0973589263697916}, {'colsample_bytree': 0.45638528973770354, 'learning_rate': 0.00403281441127091, 'num_leaves': 31, 'objective': 'poisson', 'reg_alpha': 1.4016176992297287, 'reg_lambda': 2.1171022223200797}, {'colsample_bytree': 0.15806416139462698, 'learning_rate': 0.1762735496350967, 'num_leaves': 52, 'objective': 'poisson', 'reg_alpha': 1.193299506542173, 'reg_lambda': 0.3998512474886332}, {'colsample_bytree': 0.8982083957335393, 'learning_rate': 0.11596861906319711, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 3.4287199600411267, 'reg_lambda': 0.6931730491062511}, {'colsample_bytree': 0.29113827278801396, 'learning_rate': 0.007795019328192453, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 0.296553099661214, 'reg_lambda': 0.7059952234307101}, {'colsample_bytree': 0.67447235712385, 'learning_rate': 0.19362912528256127, 'num_leaves': 55, 'objective': 'poisson', 'reg_alpha': 0.30106597093900184, 'reg_lambda': 0.022977943319227267}, {'colsample_bytree': 0.46366248687252953, 'learning_rate': 0.004161897804514534, 'num_leaves': 38, 'objective': 'regression', 'reg_alpha': 0.12799189677278577, 'reg_lambda': 0.7170142416237668}, {'colsample_bytree': 0.23288132378911566, 'learning_rate': 0.08527641241310609, 'num_leaves': 44, 'objective': 'regression', 'reg_alpha': 0.16915354827791498, 'reg_lambda': 2.0673749509499113}, {'colsample_bytree': 0.2737198732071229, 'learning_rate': 0.20579163251957563, 'num_leaves': 14, 'objective': 'poisson', 'reg_alpha': 0.6162061325716566, 'reg_lambda': 0.8384101509007209}, {'colsample_bytree': 0.5149314294604318, 'learning_rate': 0.15253372042971425, 'num_leaves': 20, 'objective': 'poisson', 'reg_alpha': 0.2576212283874702, 'reg_lambda': 0.0704391178347954}, {'colsample_bytree': 0.6299847075032537, 'learning_rate': 0.062400794055480095, 'num_leaves': 24, 'objective': 'regression', 'reg_alpha': 2.8163048756804674, 'reg_lambda': 1.24520359643369}, {'colsample_bytree': 0.7780254658530212, 'learning_rate': 0.26049751934184057, 'num_leaves': 54, 'objective': 'poisson', 'reg_alpha': 1.8632262414049605, 'reg_lambda': 0.9504901613147487}, {'colsample_bytree': 0.7595375510973837, 'learning_rate': 0.03080266974973478, 'num_leaves': 50, 'objective': 'regression', 'reg_alpha': 0.556939754829891, 'reg_lambda': 0.762774851945413}, {'colsample_bytree': 0.8432477888812052, 'learning_rate': 0.06778299847365227, 'num_leaves': 16, 'objective': 'poisson', 'reg_alpha': 0.24943291894012334, 'reg_lambda': 0.789932502665247}, {'colsample_bytree': 0.4298482718301969, 'learning_rate': 0.14890822107759868, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 0.3274949775772318, 'reg_lambda': 0.16460689292145095}, {'colsample_bytree': 0.5157343397802021, 'learning_rate': 0.05194847550994865, 'num_leaves': 21, 'objective': 'regression', 'reg_alpha': 1.112625161369371, 'reg_lambda': 0.37630715242820967}, {'colsample_bytree': 0.9720707082182733, 'learning_rate': 0.02223147481204618, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 0.061032212836918974, 'reg_lambda': 0.12763153958162368}, {'colsample_bytree': 0.1057809698163946, 'learning_rate': 0.019005172416508367, 'num_leaves': 29, 'objective': 'regression', 'reg_alpha': 0.04819589137841335, 'reg_lambda': 4.399592595290536}, {'colsample_bytree': 0.45777167008535924, 'learning_rate': 0.1702152279519259, 'num_leaves': 34, 'objective': 'regression', 'reg_alpha': 0.4379962334541965, 'reg_lambda': 1.6735780639672646}, {'colsample_bytree': 0.5099063784491388, 'learning_rate': 0.13838276125950097, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 1.3249008389583832, 'reg_lambda': 0.5824164985569723}, {'colsample_bytree': 0.6424339307842207, 'learning_rate': 0.33802739597375675, 'num_leaves': 53, 'objective': 'regression', 'reg_alpha': 0.2404124199873754, 'reg_lambda': 0.5140272178207688}, {'colsample_bytree': 0.8232890957004106, 'learning_rate': 0.1610211212470255, 'num_leaves': 47, 'objective': 'regression', 'reg_alpha': 7.032862828180445, 'reg_lambda': 0.2213873239043799}, {'colsample_bytree': 0.6065803143820755, 'learning_rate': 0.04513576683791684, 'num_leaves': 30, 'objective': 'poisson', 'reg_alpha': 0.6081214412279128, 'reg_lambda': 0.46970528721504406}, {'colsample_bytree': 0.20717162343087409, 'learning_rate': 0.004979459852160546, 'num_leaves': 14, 'objective': 'regression', 'reg_alpha': 2.155719877834787, 'reg_lambda': 1.0378299606675463}, {'colsample_bytree': 0.4345769484179547, 'learning_rate': 0.07826162423718752, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 0.09727734084740684, 'reg_lambda': 0.14900598645159147}, {'colsample_bytree': 0.5808306003455865, 'learning_rate': 0.03324367057236511, 'num_leaves': 56, 'objective': 'poisson', 'reg_alpha': 0.8704715471165867, 'reg_lambda': 2.177911052329398}, {'colsample_bytree': 0.18055710557046065, 'learning_rate': 0.015335096913388514, 'num_leaves': 38, 'objective': 'poisson', 'reg_alpha': 0.41997791245385685, 'reg_lambda': 0.5278455190044622}, {'colsample_bytree': 0.6761192701579011, 'learning_rate': 0.14496618711076464, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 1.8939882246265665, 'reg_lambda': 0.3538560722519924}, {'colsample_bytree': 0.8047230126510647, 'learning_rate': 0.0258886597364877, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 1.3045581493089706, 'reg_lambda': 3.0172675092952055}, {'colsample_bytree': 0.7870105725502932, 'learning_rate': 0.12605900111298482, 'num_leaves': 34, 'objective': 'poisson', 'reg_alpha': 0.016891495730507022, 'reg_lambda': 0.09734568277756701}, {'colsample_bytree': 0.8069181625033763, 'learning_rate': 0.09190393108750827, 'num_leaves': 57, 'objective': 'regression', 'reg_alpha': 1.0825134171076947, 'reg_lambda': 3.825350329176527}, {'colsample_bytree': 0.6262055719182124, 'learning_rate': 0.07266987254802497, 'num_leaves': 40, 'objective': 'poisson', 'reg_alpha': 0.4498641868731396, 'reg_lambda': 1.2887573657456028}, {'colsample_bytree': 0.7995605365888756, 'learning_rate': 0.08159582889435449, 'num_leaves': 12, 'objective': 'regression', 'reg_alpha': 0.5572816079716859, 'reg_lambda': 0.32396044696833626}, {'colsample_bytree': 0.3782803427160889, 'learning_rate': 0.1328809343392834, 'num_leaves': 48, 'objective': 'poisson', 'reg_alpha': 1.3876728600507293, 'reg_lambda': 0.06267991685873794}, {'colsample_bytree': 0.7733101394595191, 'learning_rate': 0.04784670665840694, 'num_leaves': 31, 'objective': 'regression', 'reg_alpha': 0.32349880796475544, 'reg_lambda': 1.2589003976619566}, {'colsample_bytree': 0.7147223886772507, 'learning_rate': 0.2309972835688647, 'num_leaves': 29, 'objective': 'regression', 'reg_alpha': 0.8217766436698991, 'reg_lambda': 0.5033734985491038}, {'colsample_bytree': 0.908892585339458, 'learning_rate': 0.08968229348339007, 'num_leaves': 27, 'objective': 'poisson', 'reg_alpha': 1.0090612291924368, 'reg_lambda': 0.9695869903502793}, {'colsample_bytree': 0.24021276759037746, 'learning_rate': 0.026426887899814646, 'num_leaves': 57, 'objective': 'poisson', 'reg_alpha': 0.6108804061099746, 'reg_lambda': 2.547601588082449}, {'colsample_bytree': 0.9758123942682394, 'learning_rate': 0.22304569271488361, 'num_leaves': 51, 'objective': 'poisson', 'reg_alpha': 0.5613255178423406, 'reg_lambda': 0.9019895340454528}, {'colsample_bytree': 0.39787851547533826, 'learning_rate': 0.007601399651179419, 'num_leaves': 42, 'objective': 'regression', 'reg_alpha': 0.37127537659320947, 'reg_lambda': 1.2715176991823145}, {'colsample_bytree': 0.4944660604721455, 'learning_rate': 0.06763878550195272, 'num_leaves': 50, 'objective': 'regression', 'reg_alpha': 1.5984009629117109, 'reg_lambda': 0.6877522832339353}, {'colsample_bytree': 0.6351759691377785, 'learning_rate': 0.14678551275726168, 'num_leaves': 46, 'objective': 'regression', 'reg_alpha': 0.36777644356544226, 'reg_lambda': 0.9939840679048441}, {'colsample_bytree': 0.2362602711914543, 'learning_rate': 0.02629895604833439, 'num_leaves': 35, 'objective': 'regression', 'reg_alpha': 0.10050102902180082, 'reg_lambda': 9.082896831330372}, {'colsample_bytree': 0.45691776900368386, 'learning_rate': 0.03100838803589906, 'num_leaves': 15, 'objective': 'regression', 'reg_alpha': 1.9595875273292889, 'reg_lambda': 0.08601527348596538}, {'colsample_bytree': 0.8165162446037298, 'learning_rate': 0.2510202253073454, 'num_leaves': 24, 'objective': 'poisson', 'reg_alpha': 0.13638968850787095, 'reg_lambda': 1.1583771460628618}, {'colsample_bytree': 0.5151478748397048, 'learning_rate': 0.2753190824945859, 'num_leaves': 54, 'objective': 'poisson', 'reg_alpha': 2.409961615213128, 'reg_lambda': 0.20226579782719933}, {'colsample_bytree': 0.5353763300650954, 'learning_rate': 0.10812119130517, 'num_leaves': 32, 'objective': 'poisson', 'reg_alpha': 1.2654509709938693, 'reg_lambda': 0.1954409434877148}, {'colsample_bytree': 0.59256981554922, 'learning_rate': 0.197284135057062, 'num_leaves': 21, 'objective': 'poisson', 'reg_alpha': 1.4095631717207646, 'reg_lambda': 0.28478997419406377}, {'colsample_bytree': 0.8933758689780991, 'learning_rate': 0.017981441553081894, 'num_leaves': 35, 'objective': 'regression', 'reg_alpha': 0.7338613877154541, 'reg_lambda': 0.16705878033872745}, {'colsample_bytree': 0.26944630861610824, 'learning_rate': 0.09320926400146927, 'num_leaves': 43, 'objective': 'poisson', 'reg_alpha': 0.7367436583897459, 'reg_lambda': 3.3762061038743534}, {'colsample_bytree': 0.26260606062524383, 'learning_rate': 0.08206280487820534, 'num_leaves': 52, 'objective': 'poisson', 'reg_alpha': 1.292769300208778, 'reg_lambda': 1.2963096419449256}, {'colsample_bytree': 0.7104592135662116, 'learning_rate': 0.04303124240226937, 'num_leaves': 22, 'objective': 'regression', 'reg_alpha': 0.3706932648254344, 'reg_lambda': 0.5317046353767466}, {'colsample_bytree': 0.8059437162573423, 'learning_rate': 0.018280912718509845, 'num_leaves': 55, 'objective': 'regression', 'reg_alpha': 0.36490410406377927, 'reg_lambda': 0.2011071443467506}, {'colsample_bytree': 0.8228271593255101, 'learning_rate': 0.08827562827057835, 'num_leaves': 37, 'objective': 'regression', 'reg_alpha': 0.06899666044057706, 'reg_lambda': 1.1559796383213883}, {'colsample_bytree': 0.5803092738606407, 'learning_rate': 0.03676918354378766, 'num_leaves': 53, 'objective': 'regression', 'reg_alpha': 1.545214859422096, 'reg_lambda': 1.9622878505763126}, {'colsample_bytree': 0.8052765768665858, 'learning_rate': 0.20307784082849772, 'num_leaves': 35, 'objective': 'poisson', 'reg_alpha': 0.9793504929693809, 'reg_lambda': 0.40124468743440195}, {'colsample_bytree': 0.40663206839129906, 'learning_rate': 0.1828468098989392, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.041502697857080675, 'reg_lambda': 0.12632601660470436}, {'colsample_bytree': 0.8404673107445133, 'learning_rate': 0.003635735313392364, 'num_leaves': 38, 'objective': 'regression', 'reg_alpha': 0.7798528680260858, 'reg_lambda': 0.5114618611465593}, {'colsample_bytree': 0.8015039430919477, 'learning_rate': 0.22534190269565135, 'num_leaves': 46, 'objective': 'regression', 'reg_alpha': 0.13421023924469475, 'reg_lambda': 0.25465651392505473}, {'colsample_bytree': 0.7224476749319684, 'learning_rate': 0.05359881733594344, 'num_leaves': 33, 'objective': 'regression', 'reg_alpha': 0.009048873593597094, 'reg_lambda': 1.5922951394660765}, {'colsample_bytree': 0.38796851970907553, 'learning_rate': 0.012312041715874602, 'num_leaves': 30, 'objective': 'regression', 'reg_alpha': 1.5413250733967796, 'reg_lambda': 0.003965400703110736}, {'colsample_bytree': 0.1661082926884708, 'learning_rate': 0.09313113521012406, 'num_leaves': 55, 'objective': 'regression', 'reg_alpha': 0.7081762391934214, 'reg_lambda': 0.7509643517682258}, {'colsample_bytree': 0.8258225949520992, 'learning_rate': 0.24650978657602943, 'num_leaves': 44, 'objective': 'regression', 'reg_alpha': 0.12638613026142723, 'reg_lambda': 0.053747694886909426}, {'colsample_bytree': 0.3019732176075895, 'learning_rate': 0.012904096210348714, 'num_leaves': 28, 'objective': 'regression', 'reg_alpha': 0.357071768791901, 'reg_lambda': 0.1759446640903645}, {'colsample_bytree': 0.5089736767734521, 'learning_rate': 0.20220893093648287, 'num_leaves': 15, 'objective': 'poisson', 'reg_alpha': 0.6743141604040909, 'reg_lambda': 1.107662591171944}, {'colsample_bytree': 0.6623876528985237, 'learning_rate': 0.011419963622314391, 'num_leaves': 16, 'objective': 'poisson', 'reg_alpha': 0.2259392788894292, 'reg_lambda': 0.3425217938419947}, {'colsample_bytree': 0.3135242177052996, 'learning_rate': 0.009877030399307228, 'num_leaves': 19, 'objective': 'regression', 'reg_alpha': 0.3272274237500469, 'reg_lambda': 4.396001821089411}, {'colsample_bytree': 0.4997818813319299, 'learning_rate': 0.19333962789115622, 'num_leaves': 36, 'objective': 'regression', 'reg_alpha': 2.0977386874734725, 'reg_lambda': 0.2315537310459832}, {'colsample_bytree': 0.1666798605381861, 'learning_rate': 0.0018279261941646292, 'num_leaves': 13, 'objective': 'regression', 'reg_alpha': 0.7305281705877599, 'reg_lambda': 2.4273326820025583}, {'colsample_bytree': 0.7124946614291792, 'learning_rate': 0.07896609608289766, 'num_leaves': 25, 'objective': 'regression', 'reg_alpha': 0.8989863875863553, 'reg_lambda': 0.8812086039399788}, {'colsample_bytree': 0.5370090554256027, 'learning_rate': 0.035561460288336615, 'num_leaves': 36, 'objective': 'poisson', 'reg_alpha': 0.06550704501491343, 'reg_lambda': 0.8819737278203663}, {'colsample_bytree': 0.4470269769191365, 'learning_rate': 0.10159089652837348, 'num_leaves': 30, 'objective': 'regression', 'reg_alpha': 1.068685693259635, 'reg_lambda': 0.37495889430239343}, {'colsample_bytree': 0.8292078675622013, 'learning_rate': 0.11251272983731386, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 1.9066143846955315, 'reg_lambda': 0.024354731351181096}, {'colsample_bytree': 0.7849490642198346, 'learning_rate': 0.14957223373320247, 'num_leaves': 59, 'objective': 'regression', 'reg_alpha': 0.14402283216884765, 'reg_lambda': 0.6831290577786621}, {'colsample_bytree': 0.2967475348648317, 'learning_rate': 0.034728788392836385, 'num_leaves': 16, 'objective': 'poisson', 'reg_alpha': 1.6577085723621234, 'reg_lambda': 0.045359322042906235}, {'colsample_bytree': 0.4383678370326952, 'learning_rate': 0.01575237923495488, 'num_leaves': 35, 'objective': 'poisson', 'reg_alpha': 0.08073189668722404, 'reg_lambda': 1.116783805181496}, {'colsample_bytree': 0.6883639949386551, 'learning_rate': 0.1793077392923187, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 1.4394817632810433, 'reg_lambda': 0.25225316136700543}, {'colsample_bytree': 0.44730871160993046, 'learning_rate': 0.2344951678621305, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 1.037123239191284, 'reg_lambda': 0.22053239474813136}, {'colsample_bytree': 0.9704232434679176, 'learning_rate': 0.026171409661677043, 'num_leaves': 51, 'objective': 'poisson', 'reg_alpha': 0.9829201844093749, 'reg_lambda': 0.28675745188236407}, {'colsample_bytree': 0.9308438349148834, 'learning_rate': 0.09101047586881111, 'num_leaves': 24, 'objective': 'regression', 'reg_alpha': 1.6624000510022916, 'reg_lambda': 1.850289539496446}, {'colsample_bytree': 0.385886115942048, 'learning_rate': 0.040054425671162665, 'num_leaves': 43, 'objective': 'poisson', 'reg_alpha': 1.303566423305742, 'reg_lambda': 2.0068731523490344}, {'colsample_bytree': 0.5261206267708649, 'learning_rate': 0.033152920692194665, 'num_leaves': 39, 'objective': 'poisson', 'reg_alpha': 2.4103028479708426, 'reg_lambda': 0.04034280914126653}, {'colsample_bytree': 0.8201289510249773, 'learning_rate': 0.04032794610301893, 'num_leaves': 21, 'objective': 'regression', 'reg_alpha': 1.3114400920352125, 'reg_lambda': 0.7858032581887832}, {'colsample_bytree': 0.5329109575032456, 'learning_rate': 0.02768130022446208, 'num_leaves': 36, 'objective': 'poisson', 'reg_alpha': 1.890129412663878, 'reg_lambda': 1.6436478475014096}, {'colsample_bytree': 0.5665466417976379, 'learning_rate': 0.23198305790338664, 'num_leaves': 12, 'objective': 'poisson', 'reg_alpha': 0.4063787089478814, 'reg_lambda': 0.5440752332468723}, {'colsample_bytree': 0.11595889480298804, 'learning_rate': 0.05827023017060176, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 1.2860291781478375, 'reg_lambda': 0.9967750551004213}, {'colsample_bytree': 0.20902859813886768, 'learning_rate': 0.03763438744879135, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 0.031765994651299256, 'reg_lambda': 0.7334365750972466}, {'colsample_bytree': 0.6095554759088277, 'learning_rate': 0.0155506257450672, 'num_leaves': 20, 'objective': 'poisson', 'reg_alpha': 2.4526626470620867, 'reg_lambda': 0.0669851515058275}, {'colsample_bytree': 0.11484128004489738, 'learning_rate': 0.05237595334827582, 'num_leaves': 52, 'objective': 'regression', 'reg_alpha': 3.414066759092168, 'reg_lambda': 1.8978178706444002}, {'colsample_bytree': 0.9402993079145765, 'learning_rate': 0.0024234918474434295, 'num_leaves': 33, 'objective': 'poisson', 'reg_alpha': 0.5749733634736519, 'reg_lambda': 0.4106787084278139}, {'colsample_bytree': 0.972940938258162, 'learning_rate': 0.02861097599219288, 'num_leaves': 44, 'objective': 'poisson', 'reg_alpha': 0.7263296260089016, 'reg_lambda': 0.2857022371875775}, {'colsample_bytree': 0.15633889152293817, 'learning_rate': 0.08845434236678876, 'num_leaves': 23, 'objective': 'regression', 'reg_alpha': 0.7838211133659364, 'reg_lambda': 0.5741794399850358}, {'colsample_bytree': 0.6999585630579214, 'learning_rate': 0.14252835385552787, 'num_leaves': 54, 'objective': 'regression', 'reg_alpha': 1.0638845276847229, 'reg_lambda': 1.7587446932453694}, {'colsample_bytree': 0.7137238120071548, 'learning_rate': 0.01558872576434775, 'num_leaves': 30, 'objective': 'poisson', 'reg_alpha': 0.28616144517937714, 'reg_lambda': 0.002059598993947836}, {'colsample_bytree': 0.34284897090432787, 'learning_rate': 0.08659777814555442, 'num_leaves': 59, 'objective': 'regression', 'reg_alpha': 0.44826373711890144, 'reg_lambda': 0.020791013334629606}, {'colsample_bytree': 0.1492273147390387, 'learning_rate': 0.15835738678180444, 'num_leaves': 15, 'objective': 'regression', 'reg_alpha': 1.7905958926343621, 'reg_lambda': 0.16170210576778277}, {'colsample_bytree': 0.16976930096837606, 'learning_rate': 0.13755602521281593, 'num_leaves': 50, 'objective': 'poisson', 'reg_alpha': 0.6743699374981261, 'reg_lambda': 0.001301045058197504}, {'colsample_bytree': 0.856316562864809, 'learning_rate': 0.031368526171166054, 'num_leaves': 13, 'objective': 'poisson', 'reg_alpha': 0.016569013717578778, 'reg_lambda': 1.3883290775218184}, {'colsample_bytree': 0.13591344605956826, 'learning_rate': 0.018398110885914594, 'num_leaves': 52, 'objective': 'regression', 'reg_alpha': 0.48165795558327834, 'reg_lambda': 1.2856550895888998}, {'colsample_bytree': 0.2080516155897475, 'learning_rate': 0.03798156680730207, 'num_leaves': 39, 'objective': 'poisson', 'reg_alpha': 0.3634360976782357, 'reg_lambda': 0.27329266033688077}, {'colsample_bytree': 0.10581891089920381, 'learning_rate': 0.02156176993256023, 'num_leaves': 34, 'objective': 'regression', 'reg_alpha': 0.4497020308883731, 'reg_lambda': 0.9594612606352327}, {'colsample_bytree': 0.8668917995838026, 'learning_rate': 0.10353637943763289, 'num_leaves': 13, 'objective': 'regression', 'reg_alpha': 0.3915247014395856, 'reg_lambda': 0.6955338005952986}, {'colsample_bytree': 0.13211358261547682, 'learning_rate': 0.23846593323338558, 'num_leaves': 39, 'objective': 'regression', 'reg_alpha': 0.48364476018068264, 'reg_lambda': 0.1509917886140679}, {'colsample_bytree': 0.6878613107313024, 'learning_rate': 0.03815184099053931, 'num_leaves': 41, 'objective': 'poisson', 'reg_alpha': 0.2090900946083372, 'reg_lambda': 1.0098276688586596}, {'colsample_bytree': 0.20509891786653625, 'learning_rate': 0.26542766547000257, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 1.1639783015210483, 'reg_lambda': 1.668573854362538}, {'colsample_bytree': 0.7477710378105493, 'learning_rate': 0.060889734983300574, 'num_leaves': 43, 'objective': 'poisson', 'reg_alpha': 1.6287900070820909, 'reg_lambda': 2.389633267354604}, {'colsample_bytree': 0.6582894989892073, 'learning_rate': 0.029531624411909624, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 0.6585984222291362, 'reg_lambda': 0.21418409965480384}, {'colsample_bytree': 0.20749495826355557, 'learning_rate': 0.03215832621780017, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 0.17015696116536894, 'reg_lambda': 1.9670717703560194}, {'colsample_bytree': 0.16485752447367513, 'learning_rate': 0.11506140246353198, 'num_leaves': 18, 'objective': 'poisson', 'reg_alpha': 0.1494811337751526, 'reg_lambda': 0.16107848738732358}, {'colsample_bytree': 0.7540834345600514, 'learning_rate': 0.1349639924731957, 'num_leaves': 40, 'objective': 'regression', 'reg_alpha': 2.032314043888436, 'reg_lambda': 0.7363336416550933}, {'colsample_bytree': 0.963777722299522, 'learning_rate': 0.03733246205206642, 'num_leaves': 59, 'objective': 'poisson', 'reg_alpha': 0.5806241121703316, 'reg_lambda': 0.058278974606315884}, {'colsample_bytree': 0.8296059097110555, 'learning_rate': 0.14075586661796144, 'num_leaves': 19, 'objective': 'regression', 'reg_alpha': 0.7768978820726763, 'reg_lambda': 0.2032975979499055}, {'colsample_bytree': 0.5304601081412211, 'learning_rate': 0.019155707192077584, 'num_leaves': 41, 'objective': 'regression', 'reg_alpha': 1.1302567880812109, 'reg_lambda': 1.63176894783394}, {'colsample_bytree': 0.5949928782504383, 'learning_rate': 0.042327327732628484, 'num_leaves': 20, 'objective': 'regression', 'reg_alpha': 0.06652365469410873, 'reg_lambda': 0.4264836186083766}, {'colsample_bytree': 0.9385795527440358, 'learning_rate': 0.010366189848015248, 'num_leaves': 16, 'objective': 'regression', 'reg_alpha': 2.8131666623769473, 'reg_lambda': 0.2541232749001481}, {'colsample_bytree': 0.5942183946736928, 'learning_rate': 0.2529058868342804, 'num_leaves': 47, 'objective': 'poisson', 'reg_alpha': 0.4726143081118227, 'reg_lambda': 0.3457835417540047}, {'colsample_bytree': 0.6153575552380695, 'learning_rate': 0.07110509555863452, 'num_leaves': 51, 'objective': 'poisson', 'reg_alpha': 0.34482806663880333, 'reg_lambda': 0.954496289284621}, {'colsample_bytree': 0.1680998075774463, 'learning_rate': 0.04882632507225002, 'num_leaves': 22, 'objective': 'poisson', 'reg_alpha': 0.18943698119123942, 'reg_lambda': 1.156179937351307}, {'colsample_bytree': 0.5453634389721779, 'learning_rate': 0.04583710627987326, 'num_leaves': 52, 'objective': 'poisson', 'reg_alpha': 0.2594567276592774, 'reg_lambda': 0.43823730760234014}, {'colsample_bytree': 0.3177141796137971, 'learning_rate': 0.09319006570384314, 'num_leaves': 18, 'objective': 'regression', 'reg_alpha': 0.3030086654109492, 'reg_lambda': 2.6050213978430503}, {'colsample_bytree': 0.8320462128431236, 'learning_rate': 0.03908150645912525, 'num_leaves': 47, 'objective': 'regression', 'reg_alpha': 0.6692427867784705, 'reg_lambda': 0.08425434692486451}, {'colsample_bytree': 0.10252002908234097, 'learning_rate': 0.23132578153876704, 'num_leaves': 18, 'objective': 'poisson', 'reg_alpha': 0.681786551988037, 'reg_lambda': 1.5181067415669092}], 'split0_test_score': array([0.35004428, 0.33436825, 0.34780541, 0.35202736, 0.32401005,\n",
      "       0.34933581, 0.35167014, 0.34774583, 0.33091725, 0.33506377,\n",
      "       0.31380796, 0.33763399, 0.31812974, 0.34545339, 0.33433271,\n",
      "       0.34465324, 0.35016675, 0.34899087, 0.34993507, 0.34117991,\n",
      "       0.34909097, 0.33579489, 0.34192704, 0.32856986, 0.31928432,\n",
      "       0.35230063, 0.35573893, 0.34647242, 0.35004903, 0.34382326,\n",
      "       0.31700581, 0.31892589, 0.34133682, 0.34491899, 0.35220699,\n",
      "       0.32714333, 0.35016332, 0.34792141, 0.31505091, 0.32961187,\n",
      "       0.35265965, 0.31774451, 0.32791932, 0.34936254, 0.32131066,\n",
      "       0.35295505, 0.34644072, 0.33760303, 0.34890014, 0.30520095,\n",
      "       0.34231957, 0.35064036, 0.3427112 , 0.32992424, 0.3501836 ,\n",
      "       0.34614331, 0.33805331, 0.33885941, 0.34892883, 0.34808796,\n",
      "       0.32616379, 0.32374067, 0.32824137, 0.33331626, 0.32703576,\n",
      "       0.34872347, 0.34705871, 0.34902563, 0.31634328, 0.34454848,\n",
      "       0.323635  , 0.33475334, 0.35255478, 0.35231171, 0.35112497,\n",
      "       0.35088941, 0.35003866, 0.34729119, 0.34683687, 0.34499556,\n",
      "       0.34558205, 0.34845225, 0.33736683, 0.35083899, 0.33206754,\n",
      "       0.3511961 , 0.32767296, 0.34937164, 0.34729905, 0.34949952,\n",
      "       0.31755194, 0.33415188, 0.35205223, 0.35204065, 0.34008076,\n",
      "       0.32488762, 0.34576982, 0.33462862, 0.34732987, 0.29554568,\n",
      "       0.3479818 , 0.3403029 , 0.34820723, 0.29235219, 0.33890053,\n",
      "       0.32664107, 0.35100851, 0.35325082, 0.34707485, 0.34865066,\n",
      "       0.35190002, 0.32738174, 0.34437943, 0.34738377, 0.34007411,\n",
      "       0.34820214, 0.33179156, 0.32988572, 0.34987089, 0.34943289,\n",
      "       0.29686745, 0.34977712, 0.34565884, 0.35390336, 0.30259201,\n",
      "       0.34319691, 0.34933541, 0.35132797, 0.32167376, 0.32374957,\n",
      "       0.33217389, 0.34901743, 0.35259701, 0.31996743, 0.33779895,\n",
      "       0.34796595, 0.32438224, 0.30516256, 0.32878625, 0.33947815,\n",
      "       0.3017119 , 0.32936654, 0.34053048, 0.33478121, 0.3451675 ,\n",
      "       0.32529559, 0.35122003, 0.31813684, 0.33553406, 0.34714949,\n",
      "       0.33695561, 0.34689046, 0.34469084, 0.34514081, 0.33097926,\n",
      "       0.31485969, 0.34966778, 0.34547843, 0.35187101, 0.35065047,\n",
      "       0.35029238, 0.35329121, 0.31247037, 0.35369691, 0.34550439,\n",
      "       0.35221402, 0.3292265 , 0.35414999, 0.34018054, 0.32897835,\n",
      "       0.34894722, 0.34580263, 0.34445166, 0.34534494, 0.34690745,\n",
      "       0.31600822, 0.33299678, 0.30483306, 0.33983616, 0.31284505,\n",
      "       0.34522309, 0.35047809, 0.31483525, 0.3515915 , 0.3183129 ,\n",
      "       0.34792427, 0.35005303, 0.35162687, 0.34884718, 0.34313593,\n",
      "       0.34052851, 0.34019779, 0.35671196, 0.3423883 , 0.33022628,\n",
      "       0.31300906, 0.3439032 , 0.35084106, 0.29810456, 0.34896326,\n",
      "       0.33559201, 0.3064335 , 0.3487972 , 0.33703953, 0.31785421,\n",
      "       0.35080614, 0.33135578, 0.34984092, 0.35261381, 0.3471714 ,\n",
      "       0.34495956, 0.3540506 , 0.34351212, 0.3342384 , 0.34850577,\n",
      "       0.32972386, 0.34551081, 0.3228015 , 0.35394836, 0.34678014,\n",
      "       0.33562691, 0.33114563, 0.35232111, 0.34974751, 0.35239201,\n",
      "       0.35264235, 0.32911522, 0.34962822, 0.34682669, 0.34160305,\n",
      "       0.33201331, 0.35111738, 0.34788774, 0.35235935, 0.34140364,\n",
      "       0.30938309, 0.33436415, 0.34912565, 0.32449786, 0.34800448,\n",
      "       0.32528195, 0.32418037, 0.35436214, 0.30374919, 0.31584769,\n",
      "       0.3424932 , 0.30192337, 0.35113986, 0.33440707, 0.34561477,\n",
      "       0.3522593 , 0.33742774, 0.32293787, 0.32390216, 0.35012286,\n",
      "       0.31926958, 0.32862921, 0.35162833, 0.3387794 , 0.33515692,\n",
      "       0.33935806, 0.33185092, 0.35179777, 0.33310589, 0.33317149,\n",
      "       0.31362883, 0.33228769, 0.29237676, 0.32837645, 0.34205056,\n",
      "       0.35045076, 0.32102419, 0.3545976 , 0.34201672, 0.34618237,\n",
      "       0.31759351, 0.32276984, 0.33172535, 0.31605888, 0.35176767,\n",
      "       0.34111523, 0.33657566, 0.35338062, 0.34331669, 0.34128051,\n",
      "       0.330127  , 0.34127895, 0.34683323, 0.3363605 , 0.35386042,\n",
      "       0.33433158, 0.33809676, 0.30965194, 0.34768806, 0.34779206,\n",
      "       0.32664518, 0.34190014, 0.34960181, 0.34430793, 0.34019083]), 'split1_test_score': array([0.3533341 , 0.3392296 , 0.35201355, 0.34727771, 0.33084736,\n",
      "       0.35314468, 0.35343815, 0.3536395 , 0.33087988, 0.35010881,\n",
      "       0.32115687, 0.34629235, 0.3326439 , 0.35370187, 0.33632432,\n",
      "       0.34934668, 0.35594542, 0.35234239, 0.34807361, 0.3456217 ,\n",
      "       0.34821011, 0.34866309, 0.34401408, 0.33855367, 0.32927703,\n",
      "       0.35061033, 0.35391089, 0.35562204, 0.35423127, 0.34801413,\n",
      "       0.32518172, 0.32448507, 0.35429481, 0.34622171, 0.35536501,\n",
      "       0.33376094, 0.35760353, 0.35354186, 0.32839997, 0.33836345,\n",
      "       0.34818663, 0.32543627, 0.3337248 , 0.35745609, 0.33219614,\n",
      "       0.35349615, 0.35320722, 0.33892526, 0.3408227 , 0.31762127,\n",
      "       0.34803386, 0.3565704 , 0.35183091, 0.34556299, 0.35384325,\n",
      "       0.34064276, 0.34399764, 0.33762953, 0.35336285, 0.35666126,\n",
      "       0.33907068, 0.33114801, 0.33559708, 0.34014419, 0.3414549 ,\n",
      "       0.34890081, 0.35458695, 0.35262551, 0.33317241, 0.35626632,\n",
      "       0.33100359, 0.34737477, 0.355981  , 0.35398734, 0.35360215,\n",
      "       0.35865722, 0.35193057, 0.35120498, 0.35570498, 0.35003991,\n",
      "       0.35349639, 0.34662308, 0.34874606, 0.35307593, 0.34411429,\n",
      "       0.34942331, 0.3370317 , 0.35623858, 0.35581693, 0.3547935 ,\n",
      "       0.32938072, 0.34596494, 0.35734886, 0.35340137, 0.34054209,\n",
      "       0.31875373, 0.3429961 , 0.34020197, 0.35158179, 0.30030895,\n",
      "       0.35320694, 0.34528058, 0.3524456 , 0.29320845, 0.34313501,\n",
      "       0.33435923, 0.34973808, 0.35065168, 0.35628473, 0.34983949,\n",
      "       0.35247237, 0.33511606, 0.35306707, 0.35159272, 0.34635561,\n",
      "       0.35203265, 0.34239089, 0.33420644, 0.34950391, 0.35312769,\n",
      "       0.31462429, 0.35325062, 0.34816667, 0.35291883, 0.30830488,\n",
      "       0.34310199, 0.35260168, 0.35583572, 0.33581539, 0.33258299,\n",
      "       0.34049748, 0.35535842, 0.35283299, 0.32730465, 0.34731482,\n",
      "       0.35154794, 0.33181928, 0.31101556, 0.33651058, 0.34779976,\n",
      "       0.31326105, 0.34535734, 0.35289779, 0.34153153, 0.35002704,\n",
      "       0.33084242, 0.34983432, 0.32077243, 0.33220166, 0.34785701,\n",
      "       0.3326688 , 0.35602728, 0.34430419, 0.34757405, 0.33785791,\n",
      "       0.3283454 , 0.35668555, 0.35428431, 0.35529511, 0.35481784,\n",
      "       0.3540782 , 0.35245288, 0.32331365, 0.35544022, 0.35486409,\n",
      "       0.35536044, 0.34238157, 0.35504016, 0.34262901, 0.33523363,\n",
      "       0.35372517, 0.35235785, 0.35555502, 0.35427319, 0.35255091,\n",
      "       0.32169066, 0.34420571, 0.32017849, 0.34525548, 0.32247718,\n",
      "       0.34801303, 0.34928482, 0.32120626, 0.3499454 , 0.3287406 ,\n",
      "       0.3545889 , 0.3565979 , 0.35523794, 0.3573884 , 0.3421908 ,\n",
      "       0.35330419, 0.35129591, 0.3555718 , 0.3515275 , 0.34783059,\n",
      "       0.31961906, 0.34570058, 0.35000054, 0.29782407, 0.34712151,\n",
      "       0.35009027, 0.31032849, 0.35436219, 0.34841735, 0.32353981,\n",
      "       0.3552412 , 0.34589371, 0.35747046, 0.3512047 , 0.35876973,\n",
      "       0.35651884, 0.35491105, 0.35263395, 0.33771891, 0.35471783,\n",
      "       0.33814622, 0.34434855, 0.33241567, 0.35462359, 0.35187179,\n",
      "       0.34281193, 0.34281594, 0.34858053, 0.34504228, 0.35624949,\n",
      "       0.35315925, 0.34231294, 0.35279759, 0.35021702, 0.35152523,\n",
      "       0.34519168, 0.35378782, 0.35930666, 0.3560344 , 0.34980791,\n",
      "       0.32649398, 0.33004492, 0.35251452, 0.33262052, 0.34864088,\n",
      "       0.32493209, 0.33166699, 0.35719871, 0.32008653, 0.32380272,\n",
      "       0.34513446, 0.30435264, 0.35372846, 0.34616948, 0.34962754,\n",
      "       0.35268888, 0.3388108 , 0.3286971 , 0.33428148, 0.35159315,\n",
      "       0.32826775, 0.34528596, 0.35522834, 0.34578276, 0.34566839,\n",
      "       0.35163004, 0.34246349, 0.35467717, 0.34005734, 0.33649273,\n",
      "       0.3289333 , 0.33852688, 0.30699812, 0.34529327, 0.34887157,\n",
      "       0.34171718, 0.33456372, 0.34878481, 0.35020548, 0.34810318,\n",
      "       0.33106242, 0.3283424 , 0.33577513, 0.32299678, 0.35845701,\n",
      "       0.342078  , 0.3468574 , 0.35318744, 0.35539585, 0.34985819,\n",
      "       0.33540777, 0.34388242, 0.34880146, 0.35027724, 0.3469436 ,\n",
      "       0.34503752, 0.35314442, 0.32443418, 0.35442541, 0.35801164,\n",
      "       0.33211785, 0.35072134, 0.35538145, 0.35555921, 0.34816923]), 'split2_test_score': array([0.38549897, 0.37144982, 0.38350688, 0.37324084, 0.36133562,\n",
      "       0.3847379 , 0.37980574, 0.38562456, 0.35357163, 0.3723303 ,\n",
      "       0.34448177, 0.37612292, 0.35395119, 0.38444626, 0.36715682,\n",
      "       0.38041511, 0.38216187, 0.38404617, 0.37438415, 0.3791991 ,\n",
      "       0.37505067, 0.3746514 , 0.37425605, 0.36745032, 0.35655868,\n",
      "       0.37670778, 0.38972204, 0.38320561, 0.38403103, 0.37535225,\n",
      "       0.34894797, 0.34882084, 0.37674754, 0.37820672, 0.38229763,\n",
      "       0.36210871, 0.37904096, 0.3763107 , 0.35104196, 0.36460681,\n",
      "       0.37594847, 0.35221008, 0.36007141, 0.38432465, 0.35652015,\n",
      "       0.38146666, 0.38428707, 0.36132768, 0.36599161, 0.33004981,\n",
      "       0.37760666, 0.38292921, 0.37732104, 0.36904186, 0.38460247,\n",
      "       0.36498737, 0.37663942, 0.36968757, 0.37765093, 0.37886773,\n",
      "       0.3655814 , 0.35806151, 0.36359934, 0.36892397, 0.36405153,\n",
      "       0.37338467, 0.37941468, 0.38351948, 0.35170672, 0.38193891,\n",
      "       0.36012687, 0.37040544, 0.38286205, 0.3843538 , 0.38248087,\n",
      "       0.38214215, 0.37401487, 0.38370712, 0.38090007, 0.3774771 ,\n",
      "       0.37977251, 0.38217633, 0.37258666, 0.3780465 , 0.37134557,\n",
      "       0.38601661, 0.36499305, 0.37911345, 0.37808002, 0.38498368,\n",
      "       0.34870528, 0.3722561 , 0.38124952, 0.38447986, 0.36197793,\n",
      "       0.3388671 , 0.38018928, 0.37079597, 0.38715953, 0.31506005,\n",
      "       0.38522823, 0.3768357 , 0.38225261, 0.30344816, 0.37332639,\n",
      "       0.36080013, 0.37577432, 0.3794322 , 0.38091578, 0.38705558,\n",
      "       0.38123431, 0.36145827, 0.37738982, 0.38180817, 0.37665865,\n",
      "       0.3843536 , 0.37054067, 0.36583191, 0.377584  , 0.38873689,\n",
      "       0.33111975, 0.38130611, 0.37765858, 0.38553333, 0.33022583,\n",
      "       0.37373584, 0.38620112, 0.38617569, 0.35816245, 0.3600475 ,\n",
      "       0.36617216, 0.37982736, 0.37903441, 0.35386633, 0.37554681,\n",
      "       0.38146933, 0.35680955, 0.33288652, 0.3638127 , 0.37701979,\n",
      "       0.33197387, 0.37018199, 0.37760309, 0.37093967, 0.37725701,\n",
      "       0.35681808, 0.37891214, 0.34562134, 0.36134515, 0.38427445,\n",
      "       0.36373926, 0.38419884, 0.3804322 , 0.3753682 , 0.36623766,\n",
      "       0.3482612 , 0.38337375, 0.37776381, 0.37930198, 0.38513955,\n",
      "       0.38614293, 0.38192623, 0.34466743, 0.3820036 , 0.3859864 ,\n",
      "       0.38232572, 0.36530612, 0.38234992, 0.37339935, 0.36639095,\n",
      "       0.38376946, 0.38019492, 0.38120453, 0.3795603 , 0.38189335,\n",
      "       0.34603773, 0.37028351, 0.33599328, 0.37497711, 0.34500976,\n",
      "       0.38090826, 0.38355158, 0.34630347, 0.37860231, 0.35191172,\n",
      "       0.37870609, 0.38652905, 0.38789308, 0.38317568, 0.37765839,\n",
      "       0.37598112, 0.37546855, 0.38783243, 0.37860471, 0.37005206,\n",
      "       0.34402314, 0.37591666, 0.37845753, 0.31743203, 0.37131183,\n",
      "       0.37661471, 0.33467115, 0.38664105, 0.37491598, 0.34745756,\n",
      "       0.38194317, 0.37014648, 0.38037296, 0.37510488, 0.38444283,\n",
      "       0.37786286, 0.38609547, 0.38027428, 0.36854956, 0.38352613,\n",
      "       0.36498195, 0.37508805, 0.35565487, 0.3893775 , 0.3735401 ,\n",
      "       0.37256482, 0.36980327, 0.38371636, 0.37988572, 0.38584922,\n",
      "       0.38357434, 0.36586206, 0.38114012, 0.38155307, 0.37720957,\n",
      "       0.36946051, 0.37949029, 0.3814673 , 0.3867543 , 0.37216013,\n",
      "       0.33783226, 0.35627676, 0.38194384, 0.35996933, 0.38085012,\n",
      "       0.35314549, 0.35876355, 0.38794634, 0.33640354, 0.3489066 ,\n",
      "       0.36818913, 0.32934338, 0.38058933, 0.37453517, 0.37886639,\n",
      "       0.38065607, 0.3716104 , 0.3591912 , 0.35948353, 0.37968165,\n",
      "       0.35081564, 0.36988156, 0.38170188, 0.37354894, 0.37444006,\n",
      "       0.37449322, 0.36979336, 0.38227826, 0.37065361, 0.36338763,\n",
      "       0.34973253, 0.36995552, 0.32343156, 0.36879734, 0.38043081,\n",
      "       0.3711447 , 0.35659609, 0.37507782, 0.37811583, 0.38030022,\n",
      "       0.35541111, 0.35500504, 0.36269501, 0.34649431, 0.3834849 ,\n",
      "       0.36862489, 0.37690665, 0.38420446, 0.38036513, 0.37861956,\n",
      "       0.36098178, 0.37530003, 0.3699138 , 0.37441307, 0.37596112,\n",
      "       0.37373211, 0.37592083, 0.34298637, 0.3781857 , 0.38572837,\n",
      "       0.36230977, 0.38145541, 0.38283483, 0.37889582, 0.37596174]), 'split3_test_score': array([0.37014323, 0.34805861, 0.36745831, 0.36514936, 0.3430682 ,\n",
      "       0.36594677, 0.36987028, 0.37203124, 0.34995816, 0.35892594,\n",
      "       0.32996322, 0.36085991, 0.33790989, 0.37142393, 0.36202453,\n",
      "       0.36741907, 0.37208943, 0.3668792 , 0.36961349, 0.36091045,\n",
      "       0.37025621, 0.35819337, 0.35146016, 0.34826366, 0.3409979 ,\n",
      "       0.36777126, 0.37106929, 0.37173874, 0.37258842, 0.356721  ,\n",
      "       0.33396667, 0.33093191, 0.36448474, 0.36153984, 0.36474976,\n",
      "       0.34209767, 0.37148994, 0.36723133, 0.33231237, 0.34937371,\n",
      "       0.36380991, 0.33284607, 0.34323503, 0.36995495, 0.34045437,\n",
      "       0.36758027, 0.37248201, 0.34838159, 0.35434025, 0.31654905,\n",
      "       0.3629263 , 0.36954737, 0.36987286, 0.35473453, 0.369949  ,\n",
      "       0.35872437, 0.3581244 , 0.34839649, 0.36681902, 0.37461096,\n",
      "       0.35306501, 0.3416307 , 0.34680505, 0.34958751, 0.35328986,\n",
      "       0.35855945, 0.37198293, 0.3730955 , 0.33230787, 0.36864461,\n",
      "       0.34474238, 0.3609239 , 0.36876442, 0.37025485, 0.37142567,\n",
      "       0.37137501, 0.36292365, 0.36363523, 0.37148814, 0.36429694,\n",
      "       0.36901962, 0.35853141, 0.3591905 , 0.36969404, 0.35529686,\n",
      "       0.36923042, 0.34823113, 0.37388248, 0.36851407, 0.37203099,\n",
      "       0.33526386, 0.36158122, 0.37239028, 0.36979601, 0.3497269 ,\n",
      "       0.32606379, 0.36372603, 0.35193798, 0.36688095, 0.31592807,\n",
      "       0.37128353, 0.36055473, 0.37228546, 0.29780526, 0.35500732,\n",
      "       0.34177247, 0.36777312, 0.36918201, 0.36846065, 0.37028762,\n",
      "       0.36710563, 0.34631562, 0.36989582, 0.36619252, 0.362906  ,\n",
      "       0.37118189, 0.35195812, 0.34495981, 0.36520225, 0.3721021 ,\n",
      "       0.31568385, 0.37257074, 0.36091385, 0.3705864 , 0.30881478,\n",
      "       0.35755325, 0.363529  , 0.3721593 , 0.34047388, 0.34533545,\n",
      "       0.34698045, 0.36897295, 0.36959669, 0.3384452 , 0.36006557,\n",
      "       0.37148869, 0.33885284, 0.31362267, 0.34833206, 0.35791423,\n",
      "       0.31992626, 0.35425418, 0.36242761, 0.35277098, 0.36716172,\n",
      "       0.34262126, 0.36887069, 0.3386042 , 0.34525021, 0.35902524,\n",
      "       0.3567052 , 0.37235721, 0.36426468, 0.35523   , 0.34775859,\n",
      "       0.33507462, 0.37212772, 0.36527125, 0.37323303, 0.37057829,\n",
      "       0.37266164, 0.36954852, 0.328869  , 0.37342417, 0.37376831,\n",
      "       0.37099789, 0.35063774, 0.37092778, 0.35444896, 0.34559136,\n",
      "       0.36977164, 0.3642001 , 0.37418362, 0.36575528, 0.37371658,\n",
      "       0.33102441, 0.35838105, 0.32251312, 0.35670208, 0.33003914,\n",
      "       0.36057227, 0.36971034, 0.32952477, 0.36954296, 0.33768801,\n",
      "       0.36580568, 0.36843025, 0.37347876, 0.3714579 , 0.36119576,\n",
      "       0.37037755, 0.36182847, 0.37495039, 0.36994598, 0.35961448,\n",
      "       0.32427468, 0.36719523, 0.36498798, 0.31505696, 0.36211851,\n",
      "       0.36218436, 0.31859637, 0.37067979, 0.35884661, 0.33067168,\n",
      "       0.37072341, 0.35271362, 0.3744213 , 0.36844733, 0.36933554,\n",
      "       0.36964232, 0.37000592, 0.37265682, 0.35089702, 0.36794563,\n",
      "       0.34463766, 0.35586302, 0.34468517, 0.37477014, 0.36080503,\n",
      "       0.35394441, 0.35596324, 0.36477988, 0.36490304, 0.37306084,\n",
      "       0.37223651, 0.35264153, 0.36553849, 0.36324317, 0.36711606,\n",
      "       0.36000156, 0.37064008, 0.36921233, 0.37152113, 0.36620376,\n",
      "       0.32654124, 0.34106742, 0.37286121, 0.34650746, 0.36471781,\n",
      "       0.3352677 , 0.34241342, 0.37225381, 0.32162223, 0.3350154 ,\n",
      "       0.36253192, 0.31045875, 0.37466749, 0.35936031, 0.37002699,\n",
      "       0.37109671, 0.35813187, 0.3411073 , 0.34545115, 0.36165647,\n",
      "       0.34332021, 0.35131292, 0.37135866, 0.35651154, 0.35831604,\n",
      "       0.36673566, 0.35419896, 0.37121   , 0.34924022, 0.34847737,\n",
      "       0.33347743, 0.34739799, 0.30586624, 0.35192534, 0.36546136,\n",
      "       0.36351501, 0.33947733, 0.36330473, 0.36141878, 0.36211765,\n",
      "       0.3371465 , 0.33602288, 0.34742927, 0.32772765, 0.37356337,\n",
      "       0.35268126, 0.36036839, 0.36689478, 0.3702961 , 0.36964842,\n",
      "       0.34453518, 0.3563239 , 0.36531729, 0.36070617, 0.36928936,\n",
      "       0.36097074, 0.36631101, 0.32715635, 0.36192753, 0.37257109,\n",
      "       0.34249238, 0.36453356, 0.37186307, 0.37356405, 0.35614642]), 'split4_test_score': array([0.35144726, 0.33835068, 0.34501483, 0.34174124, 0.3278335 ,\n",
      "       0.34817746, 0.34887889, 0.35129923, 0.32724549, 0.34170785,\n",
      "       0.31769698, 0.34349973, 0.32790205, 0.34901549, 0.33825642,\n",
      "       0.34317584, 0.35191893, 0.35231204, 0.34360258, 0.34506657,\n",
      "       0.34361898, 0.34283035, 0.33469606, 0.33723336, 0.32785122,\n",
      "       0.34381294, 0.35202428, 0.34883753, 0.35266955, 0.32582247,\n",
      "       0.32369012, 0.32398253, 0.34469866, 0.3463351 , 0.34851471,\n",
      "       0.33173924, 0.35279953, 0.34567113, 0.32248869, 0.33433599,\n",
      "       0.34382551, 0.32148517, 0.33068943, 0.35110646, 0.33054864,\n",
      "       0.34657559, 0.35074231, 0.33065385, 0.33651287, 0.31931259,\n",
      "       0.34697322, 0.34623593, 0.34887294, 0.33814055, 0.3528524 ,\n",
      "       0.33577809, 0.3399954 , 0.32957731, 0.34778607, 0.34974567,\n",
      "       0.339285  , 0.32839437, 0.33336311, 0.33517843, 0.33960834,\n",
      "       0.34157127, 0.34938367, 0.3509908 , 0.32649676, 0.34683654,\n",
      "       0.32898745, 0.34267309, 0.34990927, 0.3531698 , 0.34724171,\n",
      "       0.35204384, 0.34485112, 0.34397545, 0.34859858, 0.34438646,\n",
      "       0.34728308, 0.34650428, 0.34284053, 0.35125859, 0.34099307,\n",
      "       0.34795729, 0.33533838, 0.35113723, 0.35296168, 0.35112463,\n",
      "       0.32711543, 0.34234451, 0.35084023, 0.35283289, 0.33094187,\n",
      "       0.31161777, 0.3383658 , 0.33660115, 0.34887439, 0.28716388,\n",
      "       0.35199566, 0.34329593, 0.35132014, 0.28469836, 0.34088897,\n",
      "       0.32850002, 0.34329457, 0.34796612, 0.34931986, 0.35329827,\n",
      "       0.34991649, 0.33318595, 0.34832734, 0.34793793, 0.34132634,\n",
      "       0.34955324, 0.34039018, 0.33233562, 0.33775326, 0.3517996 ,\n",
      "       0.30641713, 0.35176084, 0.34526634, 0.34891407, 0.3060952 ,\n",
      "       0.3412222 , 0.34996818, 0.35150899, 0.33128476, 0.3304192 ,\n",
      "       0.33148899, 0.34951169, 0.34906999, 0.3253954 , 0.34318439,\n",
      "       0.35157313, 0.32577929, 0.3073798 , 0.33541036, 0.34043332,\n",
      "       0.30911623, 0.33688098, 0.34628502, 0.34063813, 0.34556212,\n",
      "       0.3290077 , 0.34594815, 0.32510051, 0.32325836, 0.34284081,\n",
      "       0.33068357, 0.34844903, 0.34193888, 0.34311098, 0.33540388,\n",
      "       0.32547133, 0.34952258, 0.34480928, 0.34906082, 0.35119763,\n",
      "       0.35293492, 0.35185031, 0.32119968, 0.34888354, 0.34821931,\n",
      "       0.35164227, 0.33792493, 0.3510514 , 0.33931635, 0.33169996,\n",
      "       0.34475251, 0.34656208, 0.34696293, 0.34661059, 0.35090622,\n",
      "       0.31971653, 0.34288187, 0.3187473 , 0.3414387 , 0.32019498,\n",
      "       0.34385628, 0.34383223, 0.31813424, 0.35175236, 0.32610096,\n",
      "       0.34733776, 0.35244057, 0.3506541 , 0.34869596, 0.33985014,\n",
      "       0.34791756, 0.34295547, 0.35396278, 0.34853783, 0.3425961 ,\n",
      "       0.31558689, 0.34183938, 0.34693588, 0.28560712, 0.33220928,\n",
      "       0.34501807, 0.31122312, 0.35181871, 0.34560516, 0.3231048 ,\n",
      "       0.34089188, 0.33913053, 0.35258191, 0.3473612 , 0.35143082,\n",
      "       0.34546183, 0.35230613, 0.34959836, 0.32845031, 0.35070404,\n",
      "       0.33188758, 0.34299053, 0.33195188, 0.34889337, 0.3306212 ,\n",
      "       0.33637807, 0.33818881, 0.34566105, 0.34439648, 0.35482902,\n",
      "       0.35042934, 0.33722261, 0.34745248, 0.34485668, 0.34800017,\n",
      "       0.34333938, 0.34856025, 0.34986511, 0.34792216, 0.34661261,\n",
      "       0.32314293, 0.32834253, 0.35020081, 0.3331972 , 0.34490883,\n",
      "       0.31891539, 0.32830167, 0.35246994, 0.31306796, 0.32141225,\n",
      "       0.34525465, 0.30587721, 0.35065418, 0.3430467 , 0.34583146,\n",
      "       0.34698204, 0.33042931, 0.32676827, 0.33213749, 0.34482992,\n",
      "       0.31418737, 0.3358315 , 0.34546042, 0.34241803, 0.34350161,\n",
      "       0.34517314, 0.34064281, 0.34613706, 0.33697122, 0.33401044,\n",
      "       0.32259129, 0.33475898, 0.30495435, 0.33602268, 0.34063322,\n",
      "       0.33869218, 0.32880942, 0.34660017, 0.34142239, 0.34669495,\n",
      "       0.3245479 , 0.32502357, 0.33391815, 0.31829803, 0.34606406,\n",
      "       0.32997196, 0.3424815 , 0.35166956, 0.34840828, 0.34795767,\n",
      "       0.3328987 , 0.34220336, 0.33816847, 0.3415534 , 0.34732727,\n",
      "       0.34462894, 0.346514  , 0.31682123, 0.34847587, 0.35100755,\n",
      "       0.3311043 , 0.34833092, 0.35002737, 0.35039493, 0.34001589]), 'mean_test_score': array([0.36209327, 0.3462911 , 0.35915952, 0.35588721, 0.33741862,\n",
      "       0.36026826, 0.36073242, 0.36206772, 0.33851429, 0.35162693,\n",
      "       0.32542107, 0.3528814 , 0.33410696, 0.36080781, 0.34761863,\n",
      "       0.35700168, 0.36245618, 0.36091384, 0.3571216 , 0.35439522,\n",
      "       0.35724519, 0.35202622, 0.3492705 , 0.34401379, 0.33479345,\n",
      "       0.35824044, 0.36449287, 0.36117491, 0.36271355, 0.34994647,\n",
      "       0.32975814, 0.32942899, 0.35631215, 0.35544421, 0.36062661,\n",
      "       0.33936968, 0.36221916, 0.35813503, 0.32985842, 0.34325803,\n",
      "       0.35688593, 0.32994412, 0.33912772, 0.36244062, 0.33620563,\n",
      "       0.36041456, 0.3614315 , 0.34337814, 0.3493135 , 0.31774643,\n",
      "       0.3555716 , 0.3611844 , 0.35812141, 0.3474804 , 0.36228585,\n",
      "       0.3492551 , 0.35136171, 0.34482992, 0.35890929, 0.36159438,\n",
      "       0.34463272, 0.33659474, 0.34152086, 0.34542978, 0.34508763,\n",
      "       0.3542278 , 0.36048506, 0.36185107, 0.33200502, 0.3596466 ,\n",
      "       0.33769871, 0.3512257 , 0.36201407, 0.36281524, 0.36117483,\n",
      "       0.36302123, 0.35675161, 0.35796253, 0.36070539, 0.35623892,\n",
      "       0.3590304 , 0.35645727, 0.35214575, 0.36058257, 0.34876306,\n",
      "       0.36076451, 0.34265308, 0.36194837, 0.36053403, 0.36248615,\n",
      "       0.3316031 , 0.35125931, 0.36277596, 0.3625099 , 0.3446538 ,\n",
      "       0.32403802, 0.3542092 , 0.34683284, 0.36036499, 0.30280115,\n",
      "       0.36193889, 0.35325365, 0.36130189, 0.29430244, 0.35025136,\n",
      "       0.33841429, 0.35751756, 0.3600964 , 0.36041085, 0.361826  ,\n",
      "       0.36052555, 0.3406912 , 0.35861155, 0.35898274, 0.35346381,\n",
      "       0.36106439, 0.3474139 , 0.34144362, 0.35598271, 0.3630395 ,\n",
      "       0.3129421 , 0.36173279, 0.35553261, 0.36237099, 0.31120633,\n",
      "       0.35176183, 0.36032681, 0.36340124, 0.33748166, 0.33842658,\n",
      "       0.34346231, 0.36053729, 0.36062602, 0.33299548, 0.35278174,\n",
      "       0.36080869, 0.33552837, 0.3140132 , 0.34257005, 0.35252873,\n",
      "       0.31519753, 0.34720777, 0.35594842, 0.34813198, 0.35703478,\n",
      "       0.33691672, 0.35895688, 0.32964678, 0.33951779, 0.35622918,\n",
      "       0.34415031, 0.3615842 , 0.3551259 , 0.35328461, 0.34364715,\n",
      "       0.33040207, 0.36227517, 0.35752112, 0.36175215, 0.36247647,\n",
      "       0.3632217 , 0.36181362, 0.32610369, 0.36268947, 0.3616681 ,\n",
      "       0.36250782, 0.34509498, 0.36270364, 0.3499946 , 0.34157854,\n",
      "       0.36019292, 0.35782322, 0.36047116, 0.35830854, 0.36119455,\n",
      "       0.32689524, 0.34974937, 0.32045267, 0.35164162, 0.32611289,\n",
      "       0.35571433, 0.35937119, 0.32600052, 0.36028669, 0.33255049,\n",
      "       0.35887227, 0.36280985, 0.36377785, 0.3619127 , 0.35280597,\n",
      "       0.35762137, 0.35434889, 0.36580565, 0.35820048, 0.35006342,\n",
      "       0.32330231, 0.35491074, 0.35824442, 0.30280483, 0.35234479,\n",
      "       0.35389944, 0.31625029, 0.36245945, 0.35296454, 0.32852535,\n",
      "       0.35992094, 0.34784762, 0.36293719, 0.35894623, 0.3622297 ,\n",
      "       0.35888874, 0.3634736 , 0.35973471, 0.3439706 , 0.36107957,\n",
      "       0.34187516, 0.35276001, 0.33750146, 0.36432234, 0.35272351,\n",
      "       0.34826492, 0.34758298, 0.35901162, 0.35679483, 0.36447582,\n",
      "       0.36240812, 0.34543047, 0.35931114, 0.35733907, 0.35709044,\n",
      "       0.35000085, 0.36071893, 0.36154749, 0.36291801, 0.35523727,\n",
      "       0.32467833, 0.33801907, 0.36132891, 0.33935811, 0.35742419,\n",
      "       0.33150837, 0.33706489, 0.36484593, 0.31898552, 0.32899661,\n",
      "       0.35272042, 0.31039086, 0.3621556 , 0.35150333, 0.35799312,\n",
      "       0.36073639, 0.34728178, 0.33574003, 0.33905079, 0.35757663,\n",
      "       0.33117182, 0.3461878 , 0.36107529, 0.35140782, 0.3514162 ,\n",
      "       0.35547763, 0.34778952, 0.36121982, 0.34600534, 0.34310769,\n",
      "       0.32967228, 0.34458511, 0.30672506, 0.34608258, 0.35548917,\n",
      "       0.3531039 , 0.33609378, 0.35767295, 0.35463553, 0.35667942,\n",
      "       0.33315191, 0.33343249, 0.34230832, 0.32631488, 0.36266713,\n",
      "       0.34689413, 0.35263752, 0.36186716, 0.35955601, 0.35747247,\n",
      "       0.34078983, 0.35179747, 0.35380668, 0.35266168, 0.35867624,\n",
      "       0.35173975, 0.35599696, 0.32420965, 0.35814026, 0.36302177,\n",
      "       0.33893359, 0.35738789, 0.36194141, 0.36054399, 0.35209653]), 'std_test_score': array([0.01376853, 0.01335029, 0.01443404, 0.011628  , 0.0135557 ,\n",
      "       0.01376555, 0.01202599, 0.01446587, 0.0109605 , 0.01309159,\n",
      "       0.01092385, 0.01391218, 0.01186746, 0.01481075, 0.01400712,\n",
      "       0.01455294, 0.01253449, 0.0131172 , 0.01241215, 0.01411609,\n",
      "       0.01280709, 0.01348535, 0.01358696, 0.01327887, 0.01289487,\n",
      "       0.01211213, 0.01430958, 0.01411493, 0.01330539, 0.01621429,\n",
      "       0.01101229, 0.01041848, 0.01302003, 0.01291582, 0.01209873,\n",
      "       0.01235856, 0.01117407, 0.01178013, 0.01208698, 0.01251362,\n",
      "       0.01162258, 0.01220573, 0.01167503, 0.01311275, 0.0118379 ,\n",
      "       0.01256624, 0.01449906, 0.0106047 , 0.01038783, 0.00790792,\n",
      "       0.01300771, 0.01340664, 0.01318567, 0.01354003, 0.01314142,\n",
      "       0.01097855, 0.01445841, 0.01378941, 0.01155775, 0.01276678,\n",
      "       0.01349523, 0.01223376, 0.01259658, 0.01303093, 0.01261757,\n",
      "       0.01099636, 0.01287501, 0.01388166, 0.01153478, 0.01400994,\n",
      "       0.01319952, 0.01281598, 0.01226866, 0.01265339, 0.01350181,\n",
      "       0.01201769, 0.01045021, 0.01449229, 0.01332673, 0.01281646,\n",
      "       0.01326276, 0.01360596, 0.01252221, 0.01119131, 0.01351589,\n",
      "       0.01478869, 0.0129592 , 0.01220427, 0.01119201, 0.01381415,\n",
      "       0.01028018, 0.01376654, 0.01200514, 0.01282166, 0.01050416,\n",
      "       0.00902113, 0.01557873, 0.01340067, 0.0150963 , 0.01118896,\n",
      "       0.01413952, 0.01371032, 0.01348414, 0.00621528, 0.01282349,\n",
      "       0.01237535, 0.01219553, 0.01216238, 0.01267389, 0.01481967,\n",
      "       0.01203285, 0.01206202, 0.01279861, 0.01329746, 0.01417238,\n",
      "       0.01431267, 0.01322215, 0.0132368 , 0.01387976, 0.01518025,\n",
      "       0.01132925, 0.01276635, 0.01245515, 0.01375577, 0.00975917,\n",
      "       0.0124565 , 0.01391053, 0.01370986, 0.01206424, 0.01287543,\n",
      "       0.01270975, 0.01203626, 0.01164535, 0.01204302, 0.01354834,\n",
      "       0.01324323, 0.01180658, 0.00987597, 0.0123485 , 0.01391253,\n",
      "       0.01026071, 0.01418349, 0.01304847, 0.01280375, 0.01290777,\n",
      "       0.01151613, 0.01271842, 0.010652  , 0.01298492, 0.01500746,\n",
      "       0.01346312, 0.01446927, 0.01499206, 0.01178045, 0.01256326,\n",
      "       0.01105354, 0.01337938, 0.01254531, 0.01216718, 0.01345341,\n",
      "       0.01393615, 0.01203212, 0.01067679, 0.01274583, 0.01566031,\n",
      "       0.01216497, 0.01224586, 0.0120106 , 0.01290122, 0.01362618,\n",
      "       0.01452101, 0.01297947, 0.01470493, 0.01287068, 0.01392786,\n",
      "       0.01077621, 0.01307451, 0.00992703, 0.01307211, 0.01092511,\n",
      "       0.01391627, 0.0149255 , 0.01126194, 0.011632  , 0.01148983,\n",
      "       0.01193902, 0.013439  , 0.01461816, 0.01348394, 0.01457437,\n",
      "       0.013452  , 0.01297207, 0.0133901 , 0.01372747, 0.0137481 ,\n",
      "       0.0110394 , 0.01392122, 0.01187172, 0.01188879, 0.01341201,\n",
      "       0.0142351 , 0.0100154 , 0.01426723, 0.01299937, 0.01030677,\n",
      "       0.01462013, 0.01321148, 0.01220265, 0.01082227, 0.0134109 ,\n",
      "       0.01308113, 0.01297099, 0.01417887, 0.01433015, 0.01309361,\n",
      "       0.01267174, 0.0120574 , 0.01143603, 0.01534041, 0.01430512,\n",
      "       0.01380934, 0.01374875, 0.01396701, 0.01371438, 0.01294043,\n",
      "       0.01318332, 0.01274941, 0.01258642, 0.01369825, 0.01310545,\n",
      "       0.01318913, 0.01215607, 0.01251911, 0.01432421, 0.01184808,\n",
      "       0.00912265, 0.01013119, 0.01347897, 0.01249098, 0.01359758,\n",
      "       0.012024  , 0.01242081, 0.01349112, 0.01075852, 0.0117476 ,\n",
      "       0.01052071, 0.00987655, 0.01281398, 0.01403179, 0.01379576,\n",
      "       0.01288351, 0.01524766, 0.01321177, 0.01231659, 0.01232156,\n",
      "       0.01394292, 0.01417071, 0.01340484, 0.01255557, 0.01369495,\n",
      "       0.01318464, 0.01310527, 0.0134337 , 0.01342676, 0.0115356 ,\n",
      "       0.01204147, 0.01368245, 0.0098888 , 0.01389564, 0.01527489,\n",
      "       0.01247588, 0.0119524 , 0.01044698, 0.01378971, 0.01319802,\n",
      "       0.01289881, 0.01168241, 0.01154916, 0.01085973, 0.01388729,\n",
      "       0.01302805, 0.01444508, 0.01245449, 0.01381066, 0.01418555,\n",
      "       0.0111953 , 0.01294748, 0.01191769, 0.01365763, 0.01184092,\n",
      "       0.01390983, 0.0135782 , 0.01120558, 0.0112482 , 0.01419979,\n",
      "       0.01278958, 0.01411845, 0.01320769, 0.01339987, 0.01333459]), 'rank_test_score': array([ 36, 209,  95, 141, 251,  86,  69,  37, 244, 180, 283, 163, 260,\n",
      "        66, 201, 129,  27,  64, 126, 152, 125, 175, 194, 222, 259, 108,\n",
      "         3,  59,  18, 191, 272, 275, 135, 147,  72, 239,  34, 111, 271,\n",
      "       227, 130, 270, 241,  28, 255,  81,  53, 226, 193, 290, 143,  58,\n",
      "       112, 203,  31, 195, 184, 217, 101,  50, 219, 254, 234, 214, 216,\n",
      "       154,  79,  44, 265,  91, 248, 186,  38,  15,  60,  12, 132, 114,\n",
      "        71, 136,  96, 134, 173,  74, 196,  67, 229,  39,  77,  24, 266,\n",
      "       185,  17,  22, 218, 286, 155, 208,  83, 299,  41, 160,  55, 300,\n",
      "       187, 246, 120,  88,  82,  45,  78, 237, 105,  98, 158,  63, 204,\n",
      "       235, 139,  10, 294,  48, 144,  30, 295, 177,  84,   8, 250, 245,\n",
      "       225,  76,  73, 263, 165,  65, 258, 293, 230, 171, 292, 206, 140,\n",
      "       198, 128, 253,  99, 274, 238, 137, 221,  51, 149, 159, 224, 269,\n",
      "        32, 119,  47,  25,   9,  46, 281,  20,  49,  23, 215,  19, 190,\n",
      "       233,  87, 115,  80, 106,  57, 278, 192, 288, 179, 280, 142,  93,\n",
      "       282,  85, 264, 103,  16,   6,  42, 164, 117, 153,   1, 109, 188,\n",
      "       287, 150, 107, 298, 172, 156, 291,  26, 162, 277,  89, 199,  13,\n",
      "       100,  33, 102,   7,  90, 223,  61, 232, 166, 249,   5, 167, 197,\n",
      "       202,  97, 131,   4,  29, 213,  94, 124, 127, 189,  70,  52,  14,\n",
      "       148, 284, 247,  54, 240, 122, 267, 252,   2, 289, 276, 168, 296,\n",
      "        35, 181, 113,  68, 205, 257, 242, 118, 268, 210,  62, 183, 182,\n",
      "       146, 200,  56, 212, 228, 273, 220, 297, 211, 145, 161, 256, 116,\n",
      "       151, 133, 262, 261, 231, 279,  21, 207, 170,  43,  92, 121, 236,\n",
      "       176, 157, 169, 104, 178, 138, 285, 110,  11, 243, 123,  40,  75,\n",
      "       174])} \n",
      "\n",
      "{'colsample_bytree': 0.4298482718301969, 'learning_rate': 0.14890822107759868, 'num_leaves': 26, 'objective': 'poisson', 'reg_alpha': 0.3274949775772318, 'reg_lambda': 0.16460689292145095}\n",
      "0.3658056497814503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3575970711248538\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    'objective': ['regression', 'poisson'],\n",
    "    'num_leaves': range(12, 60),\n",
    "    'colsample_bytree': stats.uniform(loc=0.1, scale=0.9),\n",
    "    'learning_rate': stats.expon(scale=0.1),\n",
    "    'reg_alpha': stats.expon(scale=1.0),\n",
    "    'reg_lambda': stats.expon(scale=1.0)\n",
    "}\n",
    "\n",
    "lgbmmodel3 = LGBMModel()\n",
    "rsearch = RandomizedSearchCV(lgbmmodel3, params, n_iter = 300, n_jobs=-1, cv=5, scoring=gini_scorer,\n",
    "                            return_train_score=False)\n",
    "rsearch.fit(train_objects, train_labels)\n",
    "print(rsearch.cv_results_, '\\n')\n",
    "print(rsearch.best_params_)\n",
    "print(rsearch.best_score_)\n",
    "print(gini(test_labels, rsearch.best_estimator_.fit(train_objects, train_labels).predict(test_objects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3583996699587472\n"
     ]
    }
   ],
   "source": [
    "lgbmmodel4 = LGBMModel(colsample_bytree=0.4298482718301969, learning_rate=0.014890822107759868, \n",
    "                       num_leaves=26, objective='poisson', reg_alpha=0.3274949775772318, reg_lambda=0.16460689292145095,\n",
    "                      n_estimators=1000)\n",
    "preds4 = lgbmmodel4.fit(train_objects, train_labels).predict(test_objects)\n",
    "print(gini(test_labels, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3584930668791791\n"
     ]
    }
   ],
   "source": [
    "lgbmmodel5 = LGBMModel(colsample_bytree=0.4298482718301969, learning_rate=0.0014890822107759868, \n",
    "                       num_leaves=26, objective='poisson', reg_alpha=0.3274949775772318, reg_lambda=0.16460689292145095,\n",
    "                      n_estimators=10000)\n",
    "preds5 = lgbmmodel5.fit(train_objects, train_labels).predict(test_objects)\n",
    "print(gini(test_labels, preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:** модель, оптимизирующаяся с учётом распределения Пуассона, показала лучший результат как без подбора параметров, так и с ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
